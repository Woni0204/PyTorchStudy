{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "543273ac-3b24-4528-864f-bbdcb1919a1b",
   "metadata": {},
   "source": [
    "### Torch.nn 이 실제로 무엇인가?\n",
    "* PyTorch 는 여러분이 신경망(neural network)을 생성하고 학습시키는 것을 도와주기 위해서 torch.nn, torch.optim, Dataset, 그리고 DataLoader 와 같은 잘 디자인된 모듈과 클래스들을 제공함.\n",
    "* 이들의 성능을 최대한 활용하고 여러분의 문제에 맞게 커스터마이즈하기 위해서, 정확히 이들이 어떤 작업을 수행하는지 이해할 필요가 있음.\n",
    "* 이해를 증진시키기 위해서, 우리는 먼저 이들 모델들로부터 아무 피쳐도 사용하지 않고 MNIST 데이터셋에 대해 기초적인 신경망을 학습시킬 것.\n",
    "* 우리는 처음에는 가장 기초적인 PyTorch 텐서(tensor) 기능만을 사용할 것.\n",
    "* 그리고나서 우리는 점차적으로 torch.nn, torch.optim, 또는 DataLoader 로부터 한번에 하나씩 피쳐를 추가하면서, 정확히 각 부분이 어떤 일을 하는지 그리고 이것이 어떻게 코드를 더 간결하고 유연하게 만드는지 보여줄 것."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5976590c-d95b-47b5-95d6-f448dbb7c767",
   "metadata": {},
   "source": [
    "* **이 튜토리얼은 여러분이 이미 PyTorch를 설치하였고, 그리고 텐서 연사의 기초에 대해 익숙하다고 가정함.**\n",
    "* (만약 NumPy 배열(array) 연산이 익숙하다면, 여기서 사용되는 PyTorch 텐서 연산도 거의 동일하다는 것을 알게될 것.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7757be-86b6-41d9-9abc-fce37b6040df",
   "metadata": {},
   "source": [
    "### MNIST data setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e706ff4c-d097-480e-b845-10ecd51b5d26",
   "metadata": {},
   "source": [
    "* 우리는 손으로 쓴 숫자(0에서 9 사이)의 흑백 이미지로 구성된 클래식 MNIST 데이터셋을 사용할 것."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bcbeea-a300-466b-8da1-8a90befee562",
   "metadata": {},
   "source": [
    "* 우리는 경로 설정을 담당하는 (Python3 표준 라이브러리의 일부인) pathlib 을 사용할 것이고, requests 를 이용하여 데이터셋을 다운로드 할 것.\n",
    "* 우리는 모듈을 사용할 때만 임포트(import) 할 것이므로, 여러분은 매 포인트마다 정확히 어떤 것이 사용되는지 확인할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "caf676b6-68ff-4bf8-a9fb-aae7a4e10bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"https://github.com/pytorch/tutorials/raw/main/_static/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "    content = requests.get(URL + FILENAME).content\n",
    "    (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d118e174-ca55-4446-80aa-572b0b6c3656",
   "metadata": {},
   "source": [
    "* 이 데이터셋은 NumPy 배열 포맷이고, 데이터를 직렬화하기 위한 python 전용 포맷 pickle 을 이용하여 저장되어 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4a73280-2968-49b4-beaa-1ff9e245f54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb46e9b-9e0e-44e2-b3cf-3a8ca80c96cd",
   "metadata": {},
   "source": [
    "* 각 이미지는 28 x 28 형태 이고, 784 (=28x28) 크기를 가진 하나의 행으로 저장되어 있음.\n",
    "* 하나를 살펴보면 이 이미지를 2d로 재구성해야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3a35b7a-54f8-4bd7-824e-4c8dc800c864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "\n",
    "pyplot.imshow(x_train[0].reshape((28, 28)), cmap=\"gray\")\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503f5144-0df9-4d84-811e-6d094942eb92",
   "metadata": {},
   "source": [
    "* PyTorch는 NumPy 배열 보다는 torch.tensor 를 사용하므로, 우리는 데이터를 변환해야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1735a169-58d9-4802-a103-40166d8ee76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([5, 0, 4,  ..., 8, 4, 8])\n",
      "torch.Size([50000, 784])\n",
      "tensor(0) tensor(9)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x_train, y_train, x_valid, y_valid = map(\n",
    "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
    ")\n",
    "n, c = x_train.shape\n",
    "print(x_train, y_train)\n",
    "print(x_train.shape)\n",
    "print(y_train.min(), y_train.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e99340-1cae-4beb-b120-3dde8508562d",
   "metadata": {},
   "source": [
    "### Neural net from scratch (without torch.nn)\n",
    "* PyTorch 텐서 연산만으로 첫 모델을 만들어보기."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24d0ed8-d940-4d05-8a6a-edf6b30ae125",
   "metadata": {},
   "source": [
    "* PyTorch는 랜덤 또는 0으로만 이루어진 텐서를 생성하는 메소드를 제공하고, 우리는 간단한 선형 모델의 가중치(weights)와 절편(bias)을 생성하기 위해서 이것을 사용할 것.\n",
    "* 이들은 일반적인 텐서에 매우 특별한 한가지가 추가된 것.\n",
    "* 우리는 PyTorch에게 이들이 기울기(gradient)가 필요하다고 알려줌.\n",
    "* 이를 통해 PyTorch는 텐서에 행해지는 모든 연산을 기록하게 하고, 따라서 자동적으로 역전파(back-propagation) 동안에 기울기를 계산할 수 있음!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612dc932-74eb-416b-b0b7-e681cfcc751c",
   "metadata": {},
   "source": [
    "* 가중치에 대해서는 requires_grad 를 초기화(initialization) **다음에** 설정함.\n",
    "* 왜냐하면 우리는 해당 단계가 기울기에 포함되는 것을 원치 않기 때문임.\n",
    "* (PyTorch에서 _ 다음에 오는 메소드 이름은 연산이 인플레이스(in-place)로 수행되는 것을 의미함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4880e16b-8032-4765-a2ff-2b2e9a8c9280",
   "metadata": {},
   "source": [
    "* 참고\n",
    "    + Xavier intialisation 기법을 이용하여 가중치를 초기화함.\n",
    "    + $ \\frac{1}{sqrt(n)} $ 을 곱해서 초기화."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52aa200c-b09c-4e45-952c-1fe7fb7e1bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "weights = torch.randn(784, 10) / math.sqrt(784)\n",
    "weights.requires_grad_()\n",
    "bias = torch.zeros(10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca7d2ee-83ad-4e01-85f9-0a3014ff6adf",
   "metadata": {},
   "source": [
    "* PyTorch의 기울기를 자동으로 계산해주는 기능 덕분에, Python 표준 함수 (또는 호출 가능한 객체)를 모델로 사용할 수 있음!\n",
    "* 그러므로 간단한 선형 모델을 만들기 위해서 단순한 행렬 곱셈과 브로드캐스트(broadcast) 덧셈을 사용하여 보겠음.\n",
    "* 또한, 우리는 활성화 함수(activation function)가 필요하므로, log_softmax 를 구현하고 사용할 것.\n",
    "* PyTorch에서 많은 사전 구현된 손실 함수(loss function), 활성화 함수들이 제공되지만, 일반적인 python 을 사용하여 자신만의 함수를 쉽게 작성할 수 있음을 기억.\n",
    "* PyTorch는 심지어 여러분의 함수를 위해서 빠른 GPU 또는 벡터화된 CPU 코드를 만들어줄 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "179ac85b-24e9-4e63-a004-698db2be1d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
    "\n",
    "def model(xb):\n",
    "    return log_softmax(xb @ weights + bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5db1cf5-16c9-42ba-b73b-9f46b7433b9f",
   "metadata": {},
   "source": [
    "* 위에서, @ 기호는 행렬 곱셈(matrix multiplication) 연산을 나타냄.\n",
    "* 우리는 하나의 배치(batch) 데이터 (이 경우에는 64개의 이미지들)에 대하여 함수를 호출할 것.\n",
    "* 이것은 하나의 포워드 전달(forward pass)임.\n",
    "* 이 단계에서 우리는 무작위(random) 가중치로 시작했기 때문에 우리의 예측이 무작위 예측보다 전혀 나은 점이 없을 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "96696a12-b8f1-4c07-ba09-b8033e842423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.1918, -2.7570, -2.5573, -2.3342, -1.9939, -2.2579, -2.4773, -2.5542,\n",
      "        -2.3379, -1.8878], grad_fn=<SelectBackward0>) torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "bs = 64 # 배치 크기\n",
    "\n",
    "xb = x_train[0:bs] # x로부터 미니배치(mini-batch) 추출\n",
    "preds = model(xb) # 예측\n",
    "preds[0], preds.shape\n",
    "print(preds[0], preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dc8e5e-d529-4495-b5d2-48bbe263e0f3",
   "metadata": {},
   "source": [
    "*  preds 텐서(tensor)는 텐서 값 외에도, 또한 기울기 함수(gradient function)을 담고 있음.\n",
    "*  나중에 이것을 역전파(backpropagation)을 위해 사용할 것임.\n",
    "*  이제 손실함수(loss function)로 사용하기 위한 음의 로그 우도(negative log-likelihood)를 구현함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ad7eff0-1899-4785-a197-30620d34037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(input, target):\n",
    "    return -input[range(target.shape[0]), target].mean()\n",
    "\n",
    "loss_func = nll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986af51e-9bfb-4d0e-8ad9-7024177cc9c6",
   "metadata": {},
   "source": [
    "* 우리의 무작위 모델에 대한 손실을 점검해봄.\n",
    "* 나중에 역전파 이후에 개선이 있는지 확인할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2d0b3e97-ab7f-4f9a-8234-d289a46ab50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3151, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "yb = y_train[0:bs]\n",
    "print(loss_func(preds, yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ac2c91-f401-4881-b2e0-f27b518a75b9",
   "metadata": {},
   "source": [
    "* 또한, 우리 모델의 정확도(accuracy)를 계산하기 위한 함수를 구현해봄.\n",
    "* 매 예측마다, 만약 가장 큰 값의 인덱스가 목표값(target value)과 동일하다면, 그 예측은 올바른 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f7f709f-0156-41ab-8c9a-b97ff0858424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, yb):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == yb).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0560da66-03e0-4abf-81cc-870b88b4ace0",
   "metadata": {},
   "source": [
    "* 우리의 무작위 모델의 정확도를 점검해보기.\n",
    "* 그럼으로써 손실이 개선됨에 따라서 정확도가 개선되는지 확인할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a8807d9-1831-48c2-be52-1f46505367e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0781)\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(preds, yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03d60f1-e73f-4350-9f86-23ce61273ffa",
   "metadata": {},
   "source": [
    "* 이제 우리는 훈련 루프(training loop)를 실행할 수 있음.\n",
    "* 매 반복마다, 다음을 수행할 것임.\n",
    "    + 데이터의 미니배치를 선택 (bs 크기)\n",
    "    + 모델을 이용하여 예측 수행\n",
    "    + 손실 계산\n",
    "    + loss.backward() 를 이용하여 모델의 기울기 업데이터, 이 경우에는, weights 와 bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c85f55a-b702-4963-bfa0-b8929ccb589d",
   "metadata": {},
   "source": [
    "* 이제 이 기울기들을 이용하여 가중치와 절편을 업데이트 함.\n",
    "* 이것을 torch.no_grad() 컨텍스트 매니저(context manager) 내에서 실행함.\n",
    "* 왜냐하면 이러한 실행이 다음 기울기의 계산에 기록되지 않기를 원하기 때문임."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480fe0c2-63b4-4d44-9806-add1097be233",
   "metadata": {},
   "source": [
    "* 그러고나서 기울기를 0으로 설정함.\n",
    "* 그럼으로써 다음 루프(loop)에 준비하게 됨.\n",
    "* 그렇지 않으면, 기울기들은 일어난 모든 연산의 누적 집계를 기록하게 되어버림.\n",
    "* (즉, loss.backward()가 이미 저장된 것을 대체하기보단, 기존 값에 기울기를 더하게 됨.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727e5bcc-13a4-492d-9883-0d975ba35f21",
   "metadata": {},
   "source": [
    "* PyTorch 코드에 대하여 표준 python 디버거(debugger)를 사용할 수 있으므로, 매 단계마다 다양한 변수 값을 점검할 수 있음.\n",
    "* 아래에서 set_trace()를 주석 해제하여 사용해보기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a1caf03a-1238-4eb9-8170-d245b4a59b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "lr = 0.5  # 학습률(learning rate)\n",
    "epochs = 2  # 훈련에 사용할 에폭(epoch) 수\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "        #         set_trace()\n",
    "        start_i = i * bs\n",
    "        end_i = start_i + bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            weights -= weights.grad * lr\n",
    "            bias -= bias.grad * lr\n",
    "            weights.grad.zero_()\n",
    "            bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea450cb-ab2d-4bcb-ad34-2f2811a7827a",
   "metadata": {},
   "source": [
    "* 제일 간단한 신경망(neural network)의 모든 것을 밑바닥부터 생성하고 훈련함.\n",
    "* (이번에는 은닉층(hidden layer)이 없기 때문에, 로지스틱 회귀(logistic regression)임.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec3c100-5cda-47f3-afde-53a44100bfa7",
   "metadata": {},
   "source": [
    "* 이제 손실과 정확도를 이전 값들과 비교하면서 확인해보기.\n",
    "* 우리는 손실은 감소하고, 정확도가 증가하기를 기대함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c4b4a8f1-e991-4169-b457-43f27da33a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0829, grad_fn=<NegBackward0>) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bbf4d3-1c0e-4bce-adbb-c794524d429a",
   "metadata": {},
   "source": [
    "### Using torch.nn.functional\n",
    "* 이제 우리는 코드를 리팩토링(refactoring) 하겠음.\n",
    "* 그럼으로써 이전과 동일하지만, PyTorch의 nn 클래스의 장점을 활용하여 더 간결하고 유연하게 만들 것.\n",
    "* 지금부터 매 단계에서, 우리는 코드를 더 짧고, 이해하기 쉽고, 유연하게 만들어야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d3fea3-149c-4e9f-a821-18f5f300c97e",
   "metadata": {},
   "source": [
    "* 처음이면서 우리의 코드를 짧게 만들기 가장 쉬운 단계는 직접 작성한 활성화, 손실 함수를 torch.nn.functional 의 함수로 대체하는 것.\n",
    "* (관례에 따라, 일반적으로 F 네임스페이스(namespace)를 통해 임포트(import)함.)\n",
    "* 이 모듈에는 torch.nn 라이브러리의 모든 함수가 포함되어 있음.\n",
    "* (라이브러리의 다른 부분에는 클래스가 포함되어 있음.)\n",
    "* 다양한 손실 및 활성화 함수 뿐만 아니라, 풀링(pooling) 함수와 같이 신경망을 만드는데 편리한 몇 가지 함수도 여기에서 찾을 수 있음.\n",
    "* (컨볼루션(convolution) 연산, 선형(linear) 레이어, 등을 수행하는 함수도 있지만, 앞으로 보시겠지만 일반적으로 라이브러리의 다른 부분을 사용하여 더 잘 처리 할 수 있음.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ca88c7-8f79-4196-81f1-fea4123f0463",
   "metadata": {},
   "source": [
    "* 만약 여러분들이 음의 로그 우도 손실과 로그 소프트맥스 (log softmax) 활성화 함수를 사용하는 경우, PyTorch는 이 둘을 결합하는 단일 함수인 F.cross_entropy 를 제공함.\n",
    "* 따라서 모델에서 활성화 함수를 제거할 수도 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "af0b1491-19aa-4e5f-9085-098e199fb8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "loss_func = F.cross_entropy\n",
    "\n",
    "def model(xb):\n",
    "    return xb @ weights + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2601c1-574f-4167-b38e-7a7df0bea435",
   "metadata": {},
   "source": [
    "* 더이상 model 함수에서 log_softmax 를 호출하지 않고 있음.\n",
    "* 손실과 정확도가 이전과 동일한지 확인해보기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f17a7405-29c8-400c-b218-0413742110d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0829, grad_fn=<NllLossBackward0>) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7ae2db-be41-4980-a1f3-a371ebaece7c",
   "metadata": {},
   "source": [
    "### Refactor using nn.Module\n",
    "* 다음으로, 더 명확하고 간결한 훈련 루프를 위해 nn.Module 및 nn.Parameter 를 사용함.\n",
    "* 우리는 nn.Module (자체가 클래스이고 상태를 추적할 수 있는) 하위 클래스(subclass)를 만듦.\n",
    "* 이 경우에는, 포워드(forward) 단계에 대한 가중치, 절편, 그리고 메소드(method) 등을 유지하는 클래스를 만들고자 함.\n",
    "* nn.Module 은 우리가 사용할 몇 가지 속성(attribute)과 메소드를 (.parameters() 와 .zero_grad()) 같은 가지고 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fd65f6-9a7e-4207-b4ec-fc1fb8ae1e14",
   "metadata": {},
   "source": [
    "* 참고\n",
    "    + nn.Module (대문자 M) 은 PyTorch 의 특정 개념이고, 우리는 이 클래스를 많이 사용할 것.\n",
    "    + nn.Module 를 Python 의 코드를 임포트하기 위한 코드 파일인 module (소문자 m) 의 개념과 헷갈리지 않기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "09b60270-a2d8-40a7-a2cc-2b61b62c17ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Mnist_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784))\n",
    "        self.bias = nn.Parameter(torch.zeros(10))\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return xb @ self.weights + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a16cbb8-081d-4498-bf9c-47b8097428a5",
   "metadata": {},
   "source": [
    "* 함수를 사용하는 대신에 이제는 오브젝트(object) 를 사용하기 때문에, 먼저 모델을 인스턴스화(instantiate) 해야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "636769c4-8a50-4bd8-b9a3-be15d0997371",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Mnist_Logistic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ce9bd0-614c-4000-9cd4-bcfec0c5ace6",
   "metadata": {},
   "source": [
    "* 이제 우리는 이전과 동일한 방식으로 손실을 계산할 수 있음.\n",
    "* 여기서 nn.Module 오브젝트들은 마치 함수처럼 사용됨. (즉, 이들은 호출가능함.)\n",
    "* 그러나 배후에서 PyTorch 는 우리의 forward 메소드를 자동으로 호출함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "380f138f-5fa6-412d-9e9d-4a2673309c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4008, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a48c71-c861-4315-82f9-deb96da45b49",
   "metadata": {},
   "source": [
    "* 이전에는 훈련 루프를 위해 이름 별로 각 매개변수(parameter)의 값을 업데이트하고 다음과 같이 각 매개 변수에 대한 기울기들을 개별적으로 수동으로 0으로 제거해야 했음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ba3a65e7-56e2-4c24-96bf-d12d9c3ab3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    weights -= weights.grad * lr\n",
    "    bias -= bias.grad * lr\n",
    "    weights.grad.zero_()\n",
    "    bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c628715-2827-43ff-a1d2-03001996a1b2",
   "metadata": {},
   "source": [
    "* 이제 우리는 model.parameters() 및 model.zero_grad() (모두 nn.Module 에 대해 PyTorch에 의해 정의됨)를 활용하여 이러한 단계를 더 간결하게 만들고, 특히 더 복잡한 모델에 대해서 일부 매개변수를 잊어버리는 오류를 덜 발생시킬 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b317f260-787d-4d90-ae08-907ca0699d54",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'NoneType' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[1;32m----> 3\u001b[0m         p \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\n\u001b[0;32m      4\u001b[0m     model\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'NoneType' and 'float'"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for p in model.parameters():\n",
    "        p -= p.grad * lr\n",
    "    model.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbf075f-5858-485e-b97e-418db33a123a",
   "metadata": {},
   "source": [
    "* 이제 이것을 나중에 다시 실행할 수 있도록 fit 함수로 작은 훈련 루프를 감쌀 것임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "822a211f-7961-462c-a4d4-813f20d73d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range((n - 1) // bs + 1):\n",
    "            start_i = i * bs\n",
    "            end_i = start_i + bs\n",
    "            xb = x_train[start_i:end_i]\n",
    "            yb = y_train[start_i:end_i]\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= p.grad * lr\n",
    "                model.zero_grad()\n",
    "\n",
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e35af9a-1f2b-47fe-b765-c1decae226a2",
   "metadata": {},
   "source": [
    "* 손실이 줄어들었는지 다시 한번 확인해보기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b2264ce2-0b94-4d59-b659-79b4d963f16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0802, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec749ca8-df2c-4828-a70e-f54e564dfe39",
   "metadata": {},
   "source": [
    "### Refactor using nn.Linear\n",
    "* 계속해서 코드를 리팩토링 함.\n",
    "* self.weights 및 self.bias 를 수동으로 정의 및 초기화하고, xb @ self.weights + self.bias 를 계산하는 대신에, 위의 모든 것을 해줄 PyTorch 클래스인 nn.Linear 를 선형 레이어로 사용함.\n",
    "* PyTorch 에는 다양한 유형의 코드를 크게 단순화 할 수 있는 미리 정의된 레이어가 있고 이는 또한 종종 기존 코드보다 속도를 빠르게 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e991e07c-aefc-40a0-b9c5-f82f2816dad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(784, 10)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.lin(xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20822255-8cde-47c9-bb8b-705fa41d6505",
   "metadata": {},
   "source": [
    "* 이전과 같은 방식으로 모델을 인스턴스화하고 손실을 계산함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5aed99e8-e8ae-4965-a2f5-283aa3309cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2969, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = Mnist_Logistic()\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30ad34c-3600-488b-a52f-7a6afab37ce6",
   "metadata": {},
   "source": [
    "* 우리는 여전히 이전과 동일한 fit 메소드를 사용할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c00f1987-9b97-458d-86b8-d8af21af7273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0820, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "fit()\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caef7b34-6881-4d8b-bbf8-beeb95816db6",
   "metadata": {},
   "source": [
    "### Refactor using torch.optim\n",
    "* PyTorch에는 다양한 최적화(optimization) 알고리즘을 가진 패키지인 torch.optim 도 있음.\n",
    "* 각 매개변수를 수동으로 업데이트 하는 대신, 옵티마이저(optimizer)의 step 메소드를 사용하여 업데이트를 진행할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f0e271-cd27-4b41-9e8c-8de1c3cf8559",
   "metadata": {},
   "source": [
    "* 이렇게 하면 이전에 수동으로 코딩한 최적화 단계를 대체할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5421fc-76a2-4c76-9b22-baf455a211c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for p in model.parameters(): p-= p.grad * lr\n",
    "    model.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5452f83-6480-4867-a53f-ee2165144379",
   "metadata": {},
   "source": [
    "* 대신에 이렇게 말이죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44982874-ee4e-46ad-8e0f-0c62cee2e42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.step()\n",
    "opt.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a0c771-771c-4eb1-aeb5-a6a2a2e8838c",
   "metadata": {},
   "source": [
    "* optim.zero_grad() 는 기울기를 0으로 재설정 해줌.\n",
    "* 다음 미니 배치에 대한 기울기를 계산하기 전에 호출해야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "76074bdb-6e79-448d-882c-2e1f3f7e96ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e600df3-6b02-4f03-a07c-807fcf434811",
   "metadata": {},
   "source": [
    "* 나중에 다시 사용할 수 있도록 모델과 옵티마이져를 만드는 작은 함수를 정의함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ba1dcc79-a914-4313-906b-6a6a07160825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2889, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0820, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    model = Mnist_Logistic()\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "model, opt = get_model()\n",
    "print(loss_func(model(xb), yb))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "        start_i = i * bs\n",
    "        end_i = start_i + bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef4a436-0cf3-461e-9226-d0f774f83127",
   "metadata": {},
   "source": [
    "### Refactor using Dataset\n",
    "* PyTorch 에는 추상 Dataset 클래스가 있음.\n",
    "* Dataset 은 \\_len\\_ 함수 (Python의 표준 len 함수에 의해 호출됨) 및 \\_getitem\\_ 함수를 가진 어떤 것이라도 될 수 있으며, 이 함수들을 인덱싱(indexing) 하기 위한 방법으로 사용함.\n",
    "* 이 튜토리얼은 Dataset)의 하위 클래스로써, 사용자 지정 FacialLandmarkDataset 클래스를 만드는 좋은 예를 제시함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac73d89-b192-486f-9e91-da374f601c6b",
   "metadata": {},
   "source": [
    "* PyTorch 의 TensorDataset 은 텐서를 감싸는 (wrapping) Dataset 임.\n",
    "* 길이와 인덱싱 방식을 정의함으로써 텐서의 첫 번째 차원을 따라 반복, 인덱싱 및 슬라이스(slice) 하는 방법도 제공함.\n",
    "* 이렇게하면 훈련 할 때 동일한 라인에서 독립(independent) 변수와 종속(dependent) 변수에 쉽게 액세스 할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9cac9e1f-c629-4a6f-b5bb-621d1255fe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61ff18e-0ce4-4f41-8169-0a10200d8354",
   "metadata": {},
   "source": [
    "* x_train 및 y_train 모두 하나의 TensorDataset 에 합쳐질 수 있음.\n",
    "* 따라서 반복시키고 슬라이스 하기 편리함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "660cb54c-6ad8-434f-802d-95b4f5a8ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a26e1b1-1dc6-44a7-a434-e7481f58ee45",
   "metadata": {},
   "source": [
    "* 이전에는 x 및 y 값의 미니 배치를 별도로 반복해야 했음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80f5fad-567e-4ca2-9104-abcb93f32788",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb = x_train[start_i:end_i]\n",
    "yb = y_train[start_i:end_i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2429dbf-8ea2-4c17-adf4-c736b280a086",
   "metadata": {},
   "source": [
    "* 이제 이 두 단계를 함께 수행할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d19eaa7-be12-462c-8b5e-bf646560659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = train_ds[i*bs : i*bs+bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5423acd3-d53f-44ea-b21a-b3d058c48cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0819, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "        xb, yb = train_ds[i * bs: i * bs + bs]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1e491f-841c-42d4-889e-bb39a59decc7",
   "metadata": {},
   "source": [
    "### DataLoader 를 사용하여 리팩토링하기\n",
    "* PyTorch 의 DataLoader 는 배치 관리를 담당함.\n",
    "* 모든 Dataset 으로부터 DataLoader를 생성할 수 있음.\n",
    "* DataLoader 는 배치들에 대해서 반복하기 쉽게 만들어줌.\n",
    "* train_ds[i * bs : i * bs + bs] 를 사용하는 대신, Dataloader 는 매 미니매치를 자동적으로 제공함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "daf50197-cfed-42cf-8031-c87e93c3980f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dd660f-ce41-4827-9227-aa5acd7efb90",
   "metadata": {},
   "source": [
    "* 이전에는 루프가 다음과 같이 배치 (xb, yb) 를 반복함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c8a65d69-e26d-40e7-8fd5-477b598866f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range((n - 1) // bs + 1):\n",
    "    xb, yb = train_ds[i * bs : i * bs + bs]\n",
    "    pred = model(xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec6dc98-bb4e-4417-bc23-51882d11a699",
   "metadata": {},
   "source": [
    "* 이제 (xb, yb)가 DataLoader 에서 자동으로 로드되므로 루프가 훨씬 깨끗해짐."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6958f5da-7ac5-490a-9e38-82abc22102bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for xb, yb in train_dl:\n",
    "    pred = model(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "69d9b43d-dbae-4163-a0c5-8889e2d215e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0823, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for xb, yb in train_dl:\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6740f0b7-bddf-4d64-8142-ec4c98a2e77d",
   "metadata": {},
   "source": [
    "* PyTorch 의 nn.Module, nn.Parameter, Dataset 및 DataLoader 덕분에 이제 훈련 루프가 훨씬 더 작아지고 이해하기 쉬워짐.\n",
    "* 이제 실제로 효과적인 모델을 만드는 데 필요한 기본 기능을 추가해보겠음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b2ffbe-dad1-46c8-bd20-0b376aeac9e2",
   "metadata": {},
   "source": [
    "### Add validation\n",
    "* 섹션 1에서, 우리는 훈련 데이터에 사용하기 위해 합리적인 훈련 루프를 설정하려고 했음.\n",
    "* 실전에서, 과적합(overfitting)을 확인하기 위해서 **항상** 검증 데이터셋(validation set)이 있어야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a0da42-e298-4666-a34b-10d55004c1a8",
   "metadata": {},
   "source": [
    "* 훈련 데이터를 섞는(shuffling) 것은 배치와 과적합 사이의 상관관계를 방지하기 위해 중요함.\n",
    "* 반면에, 검증 손실(validation loss)은 검증 데이터셋을 섞든 안섞든 동일함.\n",
    "* 데이터를 섞는 것은 추가 시간이 걸리므로, 검증 데이터를 섞는 것은 의미가 없음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f873c16-3a85-4477-962f-1320296c6e40",
   "metadata": {},
   "source": [
    "* 검증 데이터셋에 대한 배치 크기는 학습 데이터셋 배치 크기의 2배를 사용할 것.\n",
    "* 이는 검증 데이터셋에 대해서는 역전파(backpropagation)가 필요하지 않으므로 메모리를 덜 사용하기 때문임.\n",
    "* (기울기를 저장할 필요가 없음).\n",
    "* 더 큰 배치 크기를 사용하여 손실을 더 빨리 계산하기 위해 이렇게 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c71477ce-d776-487f-a8db-ccbffc5b1d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "\n",
    "valid_ds = TensorDataset(x_valid, y_valid)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfca9ee-b42b-4cbe-8ca1-96adfc6b1cac",
   "metadata": {},
   "source": [
    "* 각 에폭이 끝날 때 검증 손실을 계산하고 프린트 할 것."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b8f8ca-c752-4c1d-a334-515fdcb45c12",
   "metadata": {},
   "source": [
    "* 훈련 전에 항상 model.train() 을 호출하고, 추론(inference) 전에 model.eval() 을 호출함.\n",
    "* 이는 nn.BatchNorm2d 및 nn.Dropout 과 같은 레이어에서 이러한 다른 단계(훈련, 추론) 에 대한 적절한 동작이 일어나게 하기 위함임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d09de8f9-16f8-478a-891b-f27fccf78b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.4002)\n",
      "1 tensor(0.2914)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for xb, yb in train_dl:\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_loss = sum(loss_func(model(xb), yb) for xb, yb in valid_dl)\n",
    "\n",
    "    print(epoch, valid_loss / len(valid_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adcfd47-c1ee-467c-9304-1783e0a19a71",
   "metadata": {},
   "source": [
    "### Create fit() and get_data()\n",
    "* 이제 우리는 우리만의 작은 리팩토링을 수행할 것.\n",
    "* 훈련 데이터셋과 검증 데이터셋 모두에 대한 손실을 계산하는 유사한 프로세스를 두 번 거치므로, 이를 하나의 배치에 대한 손실을 계산하는 자체 함수 loss_batch 로 만들어보겠음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f188e2d4-c750-42b7-9fd1-2ace0f153681",
   "metadata": {},
   "source": [
    "* 훈련 데이터셋에 대한 옵티마이저를 전달하고 이를 사용하여 역전파를 수행함.\n",
    "* 검증 데이터셋의 경우 옵티마이저를 전달하지 않으므로 메소드가 역전파를 수행하지 않음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "643902a9-16fd-43d1-864c-8eb4b144a49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299e2bb0-58e4-4b8c-980f-30e79756bdfa",
   "metadata": {},
   "source": [
    "* fit 은 모델을 훈련하고 각 에폭에 대한 훈련 및 검증 손실을 계산하는 작업을 수행함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "be25f8b2-102b-4942-8bf0-03cf1ceba84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "\n",
    "        print(epoch, val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2d0cd9-77d7-405a-ae50-a3d1369e0656",
   "metadata": {},
   "source": [
    "* get_data 는 학습 및 검증 데이터셋에 대한 dataloader 를 출력함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f35e13af-71d4-41a8-b424-75e023fc81ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs * 2),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a865c0-4fdf-4a57-b19b-444d0c6ea962",
   "metadata": {},
   "source": [
    "* 이제 dataloader 를 가져오고 모델을 훈련하는 전체 프로세스를 3줄의 코드로 실행할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ac08d9ca-8124-4d82-a431-a047f8e9571d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.3162924583673477\n",
      "1 0.30836911851763726\n"
     ]
    }
   ],
   "source": [
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "model, opt = get_model()\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62b469c-db68-496c-8b8a-df71fe4ecf95",
   "metadata": {},
   "source": [
    "* 이러한 기본 3줄의 코드를 사용하여 다양한 모델을 훈련할 수 있음.\n",
    "* 컨볼루션 신경망 (CNN) 을 훈련하는 데 사용할 수 있는지 살펴 보겠음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707bef28-dc28-48f7-a9cd-62e01e915473",
   "metadata": {},
   "source": [
    "### Switch to CNN\n",
    "* 이제 3개의 컨볼루션 레이어로 신경망을 구축할 것.\n",
    "* 이전 섹션의 어떤 함수도 모델의 형식에 대해 가정하지 않기 때문에, 별도의 수정없이 CNN을 학습하는 데 사용할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a843a877-83f8-40e5-8a4f-843f7e246378",
   "metadata": {},
   "source": [
    "* PyTorch의 사전정의된 Conv2d 클래스를 컨볼루션 레이어로 사용함.\n",
    "* 3개의 컨볼루션 레이어로 CNN을 정의함.\n",
    "* 각 컨볼루션 뒤에는 ReLU가 있음.\n",
    "* 마지막으로 평균 풀링(average pooling)을 수행함.\n",
    "* (view 는 PyTorch의 NumPy reshape 버전임.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "566f67fc-e1ed-4391-9e31-7cda256ab07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        xb = xb.view(-1, 1, 28, 28)\n",
    "        xb = F.relu(self.conv1(xb))\n",
    "        xb = F.relu(self.conv2(xb))\n",
    "        xb = F.relu(self.conv3(xb))\n",
    "        xb = F.avg_pool2d(xb, 4)\n",
    "        return xb.view(-1, xb.size(1))\n",
    "\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e71142-0b3a-461c-b8b1-fb79519faaab",
   "metadata": {},
   "source": [
    "* 모멘텀(Momentum) 은 이전 업데이트도 고려하고 일반적으로 더 빠른 훈련으로 이어지는 확률적 경사하강법(stochastic gradient descent) 의 변형임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a0975135-00d3-4015-9724-395c78956d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.3595779992580414\n",
      "1 0.248404425740242\n"
     ]
    }
   ],
   "source": [
    "model = Mnist_CNN()\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e557c6-1f9b-4f77-9a4e-c6b1133ef548",
   "metadata": {},
   "source": [
    "### Using nn.Sequential\n",
    "* torch.nn 에는 코드를 간단히 사용할 수 있는 또 다른 편리한 클래스인 Sequential 이 있음.\n",
    "* Sequential 객체는 그 안에 포함된 각 모듈을 순차적으로 실행함.\n",
    "* 이것은 우리의 신경망을 작성하는 더 간단한 방법임."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636ee1c0-a05d-47e8-a94c-a025174a7243",
   "metadata": {},
   "source": [
    "* 이를 활용하려면 주어진 함수에서 **사용자정의 레이어(custom layer)** 를 쉽게 정의할 수 있어야 함.\n",
    "* 예를 들어, PyTorch에는 view레이어가 없으므로 우리의 신경망용으로 만들어야 함.\n",
    "* Lambda 는 Sequential 로 신경망을 정의할 때 사용할 수 있는 레이어를 생성할 것임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a3a91820-84ef-4788-9758-5b95bd8aec85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "\n",
    "def preprocess(x):\n",
    "    return x.view(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cdfe29-da3c-47c8-9011-328a0e97c618",
   "metadata": {},
   "source": [
    "* Sequential 로 생성된 모듈은 간단하게 아래와 같음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "777c60f3-8676-4e4b-9dc3-fe31c9cc21d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.3955372458934784\n",
      "1 0.3087213083267212\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    Lambda(preprocess),\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AvgPool2d(4),\n",
    "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    ")\n",
    "\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbff5f42-0c84-4e40-863b-ae110f65573f",
   "metadata": {},
   "source": [
    "### Wrapping DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12bb9cc-0e44-45ec-a1b6-105b271e86f5",
   "metadata": {},
   "source": [
    "* 현재 CNN은 상당히 간결하지만, MNIST에서만 작동함.\n",
    "* 이유는\n",
    "    + 입력이 28x28의 긴 벡터라고 가정함.\n",
    "    + 최종적으로 CNN 그리드 크기는 4x4라고 가정함.\n",
    "    + (이것은 우리가 사용한 평균 풀링 커널 크기 때문임.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f7780b-a794-4914-bec1-76edb09409ed",
   "metadata": {},
   "source": [
    "* 이 두 가지 가정을 제거하여 모델이 모든 2d 단일 채널(channel) 이미지에서 작동하도록 하겠음.\n",
    "* 먼저 초기 Lambda 레이어를 제거하고 데이터 전처리를 제너레이터(generator)로 이동시킬 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b9b3c323-8175-49c6-9d00-242dfc0efc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    return x.view(-1, 1, 28, 28), y\n",
    "\n",
    "\n",
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dl)\n",
    "        for b in batches:\n",
    "            yield (self.func(*b))\n",
    "\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
    "valid_dl = WrappedDataLoader(valid_dl, preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c532654f-eaf4-4e2d-9508-24597a033640",
   "metadata": {},
   "source": [
    "* 다음으로, nn.AvgPool2d 를 nn.AdaptiveAvgPool2d 로 대체하여 우리가 가진 입력 텐서가 아니라 원하는 출력 텐서의 크기를 정의할 수 있음.\n",
    "* 결과적으로 모델은 모든 크기의 입력과 함께 작동함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c794a0b7-9e87-4a14-983c-b63f3ba56b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    ")\n",
    "\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99c5084-d8ba-4a06-a3af-8277551dca4d",
   "metadata": {},
   "source": [
    "* 한번 실행해보겠음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9083b20c-d5d1-44c1-8628-6f0cb9c7f37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5658090400695801\n",
      "1 0.4720685434818268\n"
     ]
    }
   ],
   "source": [
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be68ea0b-6490-4813-919f-f8193e4d751d",
   "metadata": {},
   "source": [
    "### Using your GPU\n",
    "* 만약 운이 좋아서 CUDA 지원 GPU (대부분의 클라우드 제공 업체에서 돈을 내거나 Colab 을 사용 가능.) 를 사용할 수 있다면, 코드 실행 속도를 높일 수 있음.\n",
    "* 먼저 GPU가 PyTorch에서 작동하는지 확인함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5e731073-96b3-4d1e-95d9-cd61227ac392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b85034-c71f-4ee8-9d84-c7d119d87c88",
   "metadata": {},
   "source": [
    "* 그리고 이에 대한 디바이스 오브젝트를 생성함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3efe4303-6fff-4111-bf36-06bd8ceba7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\n",
    "    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b25e4ee-faae-4343-8238-d0a43ec76075",
   "metadata": {},
   "source": [
    "* GPU로 배치를 옮기도록 preprocess 를 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "624feb72-3e60-4d51-a2a9-a4005f69f6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    return x.view(-1, 1, 28, 28).to(dev), y.to(dev)\n",
    "\n",
    "\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
    "valid_dl = WrappedDataLoader(valid_dl, preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5777ff-d093-48f2-a2f4-0a75deb57ca4",
   "metadata": {},
   "source": [
    "* 마지막으로 모델을 GPU로 이동시킬 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "829dadbc-f032-4de6-a302-8c59c5194250",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(dev)\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437aa5c8-dc7d-470d-9f4e-af34f18ae1d2",
   "metadata": {},
   "source": [
    "* 이제 더 빨리 실행됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5ba8f325-7323-4100-b909-a9ad418d6989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.42758629879951476\n",
      "1 0.4136501205921173\n"
     ]
    }
   ],
   "source": [
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dabd32-8d36-46ce-a217-dc14d69d71df",
   "metadata": {},
   "source": [
    "### Closing thoughts\n",
    "* 이제 PyTorch를 사용하여 다양한 유형의 모델을 학습하는 데 사용할 수 있는 일반 데이터 파이프 라인과 훈련 루프가 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d1a3f4-ffa5-459e-9f6b-f9906b958723",
   "metadata": {},
   "source": [
    "* 물론 데이터 증강(data augmentation), 초매개변수 조정(hyperparameter tuning), 훈련과정 모니터링(monitoring training), 전이 학습(transfer learning) 등과 같이 추가하고 싶은 항목들이 많이 있을 것.\n",
    "* 이러한 기능들은 이 튜토리얼에 표시된 것과 동일한 설계 접근 방식을 사용하여 개발된 fastai 라이브러리에서 사용할 수 있으며, 모델을 더욱 발전시키려는 실무자에게 자연스러운 다음 단계를 제공함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48da297e-06ea-4dad-a345-7149bddeb71b",
   "metadata": {},
   "source": [
    "* 이 튜토리얼의 시작 부분에서 torch.nn, torch.optim, Dataset, 그리고 DataLoader 의 각 예제를 통해 설명하겠다고 이야기함.\n",
    "* 위의 내용을 요약해보자면 다음과 같음.\n",
    "    + torch.nn :\n",
    "        - Module : 함수처럼 동작하지만, 또한 상태(state) (예를 들어, 신경망의 레이어 가중치)를 포함할 수 있는 호출 가능한 오브젝트를 생성함.\n",
    "        - 이는 포함된 Parameter (들)가 어떤 것인지 알고, 모든 기울기를 0으로 설정하고 가중치 업데이트 등을 위해 반복할 수 있음.\n",
    "        - Parameter : Module 에 역전파 동안 업데이트가 필요한 가중치가 있음을 알려주는 텐서용 래퍼임.\n",
    "        - requires_grad 속성이 설정된 텐서만 업데이트 됨.\n",
    "        - functional : 활성화 함수, 손실 함수 등을 포함하는 모듈 (관례에 따라 일반적으로 F 네임스페이스로 임포트 됨.) 이고, 물론 컨볼루션 및 선형 레이어 등에 대해서 상태를 저장하지 않는(non-stateful)버전의 레이어를 포함함.\n",
    "    + torch.optim : 역전파 단계에서 Parameter 의 가중치를 업데이트하는, SGD 와 같은 옵티마이저를 포함함.\n",
    "    + Dataset : TensorDataset 과 같이 PyTorch 와 함께 제공되는 클래스를 포함하여 \\_\\_len\\_\\_ 및 \\_\\_getitem\\_\\_ 이 있는 객체의 추상 인터페이스\n",
    "    + DataLoader : 모든 종류의 Dataset 을 기반으로 데이터의 배치들을 출력하는 반복자(iterator)를 생성함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eda4eb0-48fc-43f1-8eba-00e15cdd5415",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
