{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0daa747d-25f0-404e-b716-72b6acc86ff5",
   "metadata": {},
   "source": [
    "### 배포를 위해 비전 트랜스포머 (VISION TRANSFORMER) 모델 최적화하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ea7d04-87ef-48fd-8c06-67c19d29b2b2",
   "metadata": {},
   "source": [
    "* 비전 트랜스포머(Vision Transformer)는 자연어 처리 분야에서 소개된 최고 수준의 결과를 달성한 최신의 어텐션 기반(attention-based) 트랜스포머 모델을 컴퓨터 비전 분야에 적용을 한 모델임.\n",
    "* Facebook에서 발표한 Data-efficient Image Transformers는 [DeiT](https://ai.meta.com/blog/data-efficient-image-transformers-a-promising-new-technique-for-image-classification/) 이미지 분류를 위해 ImageNet 데이터셋을 통해 훈련된 비전 트랜스포머 모델임."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375d1208-4b9c-4e6b-ad2a-17804cbf2a8e",
   "metadata": {},
   "source": [
    "* 이번 튜토리얼에서는, DeiT가 무엇인지 그리고 어떻게 사용하는지 다룰 것임.\n",
    "* 그 다음 스크립팅, 양자화, 최적화, 그리고 iOS와 안드로이드 앱 안에서 모델을 사용하는 전체적인 단계를 수행해 볼 것임.\n",
    "* 또한, 양자화와 최적화가 된 모델과 양자화와 최적화가 되지 않은 모델을 비교해 볼 것이며, 단계를 수행해 가면서 양자화와 최적화를 적용한 모델이 얼마나 이점을 가지는지 볼 것임."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cec812-a70b-4e75-b656-fc928ecc97ae",
   "metadata": {},
   "source": [
    "### DeiT란 무엇인가\n",
    "* 합성곱 신경망(CNNs)은 2012년 딥러닝이 시작된 이후 이미지 분류를 수행할 때 주요한 모델이였음.\n",
    "* 그러나 합성곱 신경망은 일반적으로 최첨단의 결과를 달성하기 위해 훈련에 수억 개의 이미지가 필요했음.\n",
    "* DeiT는 훈련에 더 적은 데이터와 컴퓨팅 자원을 필요로 하는 비전 트랜스포머 모델이며, 최신 CNN 모델과 이미지 분류를 수행하는데 경쟁을 함.\n",
    "* 이는 DeiT의 두 가지 주요 구성 요소에 의해 가능하게 되었음.\n",
    "    - 훨씬 더 큰 데이터 세트에 대한 훈련을 시뮬레이션하는 데이터 증강(augmentation)\n",
    "    - 트랜스포머 네트워크에 CNN의 출력값을 그대로 증류(distillation)하여 학습할 수 있도록 하는 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e97c84-f74a-4d9a-8fe3-8aaeb14a62fc",
   "metadata": {},
   "source": [
    "* DeiT는 제한된 데이터와 자원을 활용하여 컴퓨터 비전 태스크(task)에 트랜스포머 모델을 성공적으로 적용할 수 있음을 보여줌.\n",
    "* DeiT의 좀 더 자세한 내용을 원한다면, [저장소](https://github.com/facebookresearch/deit)와 [논문](https://arxiv.org/abs/2012.12877)을 참고하시길 바람."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5479f8fa-9ba7-43f2-952b-a68629e369bd",
   "metadata": {},
   "source": [
    "### DeiT를 활용한 이미지 분류\n",
    "* DeiT를 사용하여 이미지를 분류하는 방법에 대한 자세한 정보는 DeiT 저장소의 `README.md`를 참고하시길 바람.\n",
    "* 빠른 테스트를 위해서, 먼저 필요한 패키지들을 설치함:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc602945-d2ab-4df2-8261-9f489aa4a11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\lab\\anaconda3\\envs\\study\\lib\\site-packages (1.12.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\lab\\anaconda3\\envs\\study\\lib\\site-packages (0.13.1)\n",
      "Requirement already satisfied: timm in c:\\users\\lab\\anaconda3\\envs\\study\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\lab\\anaconda3\\envs\\study\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: requests in c:\\users\\lab\\anaconda3\\envs\\study\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\lab\\anaconda3\\envs\\study\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\lab\\anaconda3\\envs\\study\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\lab\\anaconda3\\envs\\study\\lib\\site-packages (from torchvision) (9.5.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\lab\\anaconda3\\envs\\study\\lib\\site-packages (from timm) (6.0.1)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\lab\\anaconda3\\envs\\study\\lib\\site-packages (from timm) (0.23.1)\n",
      "Requirement already satisfied: safetensors in c:\\users\\lab\\anaconda3\\envs\\study\\lib\\site-packages (from timm) (0.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lab\\anaconda3\\envs\\study\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lab\\anaconda3\\envs\\study\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\lab\\anaconda3\\envs\\study\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lab\\anaconda3\\envs\\study\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lab\\anaconda3\\envs\\study\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lab\\anaconda3\\envs\\study\\lib\\site-packages (from requests) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lab\\anaconda3\\envs\\study\\lib\\site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lab\\anaconda3\\envs\\study\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\lab\\anaconda3\\envs\\study\\lib\\site-packages (from huggingface_hub->timm) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\lab\\anaconda3\\envs\\study\\lib\\site-packages (from huggingface_hub->timm) (2024.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\lab\\anaconda3\\envs\\study\\lib\\site-packages (from huggingface_hub->timm) (23.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\lab\\anaconda3\\envs\\study\\lib\\site-packages (from huggingface_hub->timm) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\lab\\anaconda3\\envs\\study\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub->timm) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision timm pandas requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeda8f8-f9b1-40d4-be75-cd9f7f31eacf",
   "metadata": {},
   "source": [
    "* Google Colab에서는 아래와 같이 실행함:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57e1e0e-d203-4436-bee8-17f395474f89",
   "metadata": {},
   "source": [
    "```\n",
    "!pip install timm pandas requests\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178edbf6-27e9-4dc4-84f0-c6f27e389d76",
   "metadata": {},
   "source": [
    "* 그런 다음 아래 스크립트를 실행함:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9c04bb7-48f4-43b9-8de3-1b5204ea209a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\lab/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "C:\\Users\\lab/.cache\\torch\\hub\\facebookresearch_deit_main\\models.py:63: UserWarning: Overwriting deit_tiny_patch16_224 in registry with models.deit_tiny_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def deit_tiny_patch16_224(pretrained=False, **kwargs):\n",
      "C:\\Users\\lab/.cache\\torch\\hub\\facebookresearch_deit_main\\models.py:78: UserWarning: Overwriting deit_small_patch16_224 in registry with models.deit_small_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def deit_small_patch16_224(pretrained=False, **kwargs):\n",
      "C:\\Users\\lab/.cache\\torch\\hub\\facebookresearch_deit_main\\models.py:93: UserWarning: Overwriting deit_base_patch16_224 in registry with models.deit_base_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def deit_base_patch16_224(pretrained=False, **kwargs):\n",
      "C:\\Users\\lab/.cache\\torch\\hub\\facebookresearch_deit_main\\models.py:108: UserWarning: Overwriting deit_tiny_distilled_patch16_224 in registry with models.deit_tiny_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def deit_tiny_distilled_patch16_224(pretrained=False, **kwargs):\n",
      "C:\\Users\\lab/.cache\\torch\\hub\\facebookresearch_deit_main\\models.py:123: UserWarning: Overwriting deit_small_distilled_patch16_224 in registry with models.deit_small_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def deit_small_distilled_patch16_224(pretrained=False, **kwargs):\n",
      "C:\\Users\\lab/.cache\\torch\\hub\\facebookresearch_deit_main\\models.py:138: UserWarning: Overwriting deit_base_distilled_patch16_224 in registry with models.deit_base_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def deit_base_distilled_patch16_224(pretrained=False, **kwargs):\n",
      "C:\\Users\\lab/.cache\\torch\\hub\\facebookresearch_deit_main\\models.py:153: UserWarning: Overwriting deit_base_patch16_384 in registry with models.deit_base_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def deit_base_patch16_384(pretrained=False, **kwargs):\n",
      "C:\\Users\\lab/.cache\\torch\\hub\\facebookresearch_deit_main\\models.py:168: UserWarning: Overwriting deit_base_distilled_patch16_384 in registry with models.deit_base_distilled_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def deit_base_distilled_patch16_384(pretrained=False, **kwargs):\n",
      "C:\\Users\\lab\\anaconda3\\envs\\study\\lib\\site-packages\\torchvision\\transforms\\transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import timm\n",
    "import requests\n",
    "import torchvision.transforms as transforms\n",
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "\n",
    "print(torch.__version__)\n",
    "# Pytorch 버전은 1.8.0 이어야 한다는데, 본인은 1.12.1임.\n",
    "\n",
    "model = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_224', pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256, interpolation=3),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD),\n",
    "])\n",
    "\n",
    "img = Image.open(requests.get(\"https://raw.githubusercontent.com/pytorch/ios-demo-app/master/HelloWorld/HelloWorld/HelloWorld/image.png\", stream=True).raw)\n",
    "img = transform(img)[None, ]\n",
    "out = model(img)\n",
    "clsidx = torch.argmax(out)\n",
    "print(clsidx.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58b9404-716d-43b2-9119-9c101c2c799c",
   "metadata": {},
   "source": [
    "* ImageNet 목록에 따라 [라벨(labels) 파일](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a) 클래스 인덱스의 출력은 269여야 하며, 이는 `timber wolf`, `grey wolf`, `Canis lupus`에 매핑됨.\n",
    "* 이제 DeiT 모델을 사용하여 이미지들을 분류할 수 있음을 확인했음.\n",
    "* iOS 및 Android 앱에서 실행할 수 있도록 모델을 수정하는 방법을 살펴보겠음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e45dd4-749b-4667-a35b-823db9b321a7",
   "metadata": {},
   "source": [
    "### DeiT 스크립팅\n",
    "* 모바일에서 이 모델을 사용하려면, 우리는 첫번째로 모델 스크립팅이 필요함.\n",
    "* 전체적인 개요는 [스크립트 그리고 최적화 레시피](https://tutorials.pytorch.kr/recipes/script_optimized.html) 에서 확인할 수 있음.\n",
    "* 아래 코드를 실행하여 이전 단계에서 사용한 DeiT 모델을 모바일에서 실행할 수 있는 TorchScript 형식으로 변환함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25938431-11f5-48e2-891a-618db14cb60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\lab/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_224', pretrained=True)\n",
    "model.eval()\n",
    "scripted_model = torch.jit.script(model)\n",
    "scripted_model.save(\"fbdeit_scripted.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1e006a-4974-47fe-ad73-8723ed03b23e",
   "metadata": {},
   "source": [
    "* 약 346MB 크기의 스크립팅된 모델 파일 `fbdeit_scripted.pt`가 생성됨."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7b93ab-2f7f-4a31-97f7-4ff744b0d84e",
   "metadata": {},
   "source": [
    "### DeiT 양자화\n",
    "* 추론 정확도를 거의 동일하게 유지하면서 훈련된 모델 크기를 크게 줄이기 위해 모델에 양자화를 적용할 수 있음.\n",
    "* DeiT에서 사용된 트랜스포머 모델 덕분에, 모델에 동적 양자화를 쉽게 적용할 수 있음.\n",
    "* 왜냐하면 동적 양자화는 LSTM 모델과 트랜스포머 모델에서 가장 잘 적용되기 때문임. (자세한 내용은 [여기](https://pytorch.org/docs/stable/quantization.html#dynamic-quantization)를 참고.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7d897b-6c8b-4674-8c01-14cfe9f347a6",
   "metadata": {},
   "source": [
    "* 아래의 코드를 실행시켜 봄."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4647973-9924-44f2-b77c-b4c5349b16d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lab\\anaconda3\\envs\\study\\lib\\site-packages\\torch\\ao\\quantization\\observer.py:176: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 서버 추론을 위해 'x86'을, 모바일 추론을 위해 ``qnnpack``을 사용함.\n",
    "# (이전의 'fbgemm' 또한 여전히 사용 가능하지만, 'x86'을 기본으로 사용하는 것을 권장함.)\n",
    "# 서버 추론을 위해 'fbgemm'을, 모바일 추론을 위해 'qnnpack'을 사용해 봄.\n",
    "backend = \"fbgemm\" # 이 주피터 노트북에서는 양자화된 모델의 더 느린 추론 속도를 일으키는 ``qnnpack`` 으로 대체됨.\n",
    "model.qconfig = torch.quantization.get_default_qconfig(backend)\n",
    "torch.backends.quantized.engine = backend\n",
    "\n",
    "quantized_model = torch.quantization.quantize_dynamic(model, qconfig_spec={torch.nn.Linear}, dtype=torch.qint8)\n",
    "scripted_quantized_model = torch.jit.script(quantized_model)\n",
    "scripted_quantized_model.save(\"fbdeit_scripted_quantized.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fef4a7-5914-44f7-909b-5254cdc602f5",
   "metadata": {},
   "source": [
    "* `fbdeit_quantized_scripted.pt` 모델의 스크립팅과 양자화가 적용된 버전이 만들어졌음.\n",
    "* 모델의 크기는 단지 89MB 임.\n",
    "* 양자화가 적용되지 않은 모델의 크기인 346MB보다 74%나 감소했음!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa609677-1c35-425b-8f46-eff006d0e3a3",
   "metadata": {},
   "source": [
    "* 동일한 추론 결과를 만들기 위해 `scripted_quantized_model`을 사용해 봄."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1755cf02-0c43-4839-8ec1-ab15bf7f8346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269\n"
     ]
    }
   ],
   "source": [
    "out = scripted_quantized_model(img)\n",
    "cllsidx = torch.argmax(out)\n",
    "print(clsidx.item())\n",
    "# 동일한 출력 결과인 269가 출력 되어야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957d747e-b0fe-44a8-be8e-5837d64be38e",
   "metadata": {},
   "source": [
    "### DeiT 최적화\n",
    "* 모바일에 스크립트 되고 양자화된 모델을 사용하기 위한 마지막 단계는 최적화임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a34021cc-6503-4e17-9b09-673a00e79a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "optimized_scripted_quantized_model = optimize_for_mobile(scripted_quantized_model)\n",
    "optimized_scripted_quantized_model.save(\"fbdeit_optimized_scripted_quantized.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c36ad2-772e-4e1e-bb3c-ccc60693eacb",
   "metadata": {},
   "source": [
    "* 생성된 `fbdeit_optimized_scripted_quantized.pt` 파일은 양자화되고 스크립트되지만 최적화되지 않은 모델과 크기가 거의 같음.\n",
    "* 추론 결과는 동일하게 유지됨."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e537cb-73b2-4ba9-b629-9bfc97e75d5b",
   "metadata": {},
   "source": [
    "### 라이트 인터프리터(Lite interpreter) 사용\n",
    "* 라이트 인터프리터를 사용하면 얼마나 모델의 사이즈가 작아지고, 추론 시간이 짧아지는지 결과를 확인해 봄.\n",
    "* 이제 좀 더 가벼운 버전의 모델을 만들어 봄."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0953cc92-c8b7-412e-9ca0-8e13e532c344",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_scripted_quantized_model._save_for_lite_interpreter(\"fbdeit_optimized_scripted_quantized_lite.ptl\")\n",
    "ptl = torch.jit.load(\"fbdeit_optimized_scripted_quantized_lite.ptl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed398e65-9442-4a92-b354-925a0dad6717",
   "metadata": {},
   "source": [
    "* 가벼운 모델의 크기는 그렇지 않은 버전의 모델 크기와 비슷하지만, 모바일에서 가벼운 버전을 실행하면 추론 속도가 빨라질 것으로 예상됨."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05285115-7b3b-4674-9541-10edcacee7c1",
   "metadata": {},
   "source": [
    "### 추론 속도 비교\n",
    "* 네 가지 모델(원본 모델, 스크립트된 모델, 스크립트와 양자화를 적용한 모델, 스크립트와 양자화를 적용한 후 최적화한 모델)의 추론 속도가 어떻게 다른지 확인해 봄."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460c2b35-3adb-465e-8cdf-ab957753373a",
   "metadata": {},
   "source": [
    "* 아래의 코드를 실행해 봄."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c186773a-2ff7-47e0-9a7a-dc2192117037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lab\\anaconda3\\envs\\study\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\c10/core/TensorImpl.h:1408.)\n",
      "  return forward_call(*input, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original model: 434.61ms\n",
      "scripted model: 414.70ms\n",
      "scripted & quantized model: 260.70ms\n",
      "scripted & quantized & optimized model: 215.87ms\n",
      "lite model: 231.92ms\n"
     ]
    }
   ],
   "source": [
    "with torch.autograd.profiler.profile(use_cuda=False) as prof1:\n",
    "    out = model(img)\n",
    "with torch.autograd.profiler.profile(use_cuda=False) as prof2:\n",
    "    out = scripted_model(img)\n",
    "with torch.autograd.profiler.profile(use_cuda=False) as prof3:\n",
    "    out = scripted_quantized_model(img)\n",
    "with torch.autograd.profiler.profile(use_cuda=False) as prof4:\n",
    "    out = optimized_scripted_quantized_model(img)\n",
    "with torch.autograd.profiler.profile(use_cuda=False) as prof5:\n",
    "    out = ptl(img)\n",
    "\n",
    "print(\"original model: {:.2f}ms\".format(prof1.self_cpu_time_total/1000))\n",
    "print(\"scripted model: {:.2f}ms\".format(prof2.self_cpu_time_total/1000))\n",
    "print(\"scripted & quantized model: {:.2f}ms\".format(prof3.self_cpu_time_total/1000))\n",
    "print(\"scripted & quantized & optimized model: {:.2f}ms\".format(prof4.self_cpu_time_total/1000))\n",
    "print(\"lite model: {:.2f}ms\".format(prof5.self_cpu_time_total/1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0d0ec2-57fa-428f-a30d-4c42eb45e4be",
   "metadata": {},
   "source": [
    "* 다음 결과는 각 모델이 소요한 추론 시간과 원본 모델에 대한 각 모델의 감소율을 요약한 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b453fbe-f5e1-4cca-958c-ab6e6c11fc91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model Inference Time Reduction\n",
      "0                          original model       434.61ms        0%\n",
      "1                          scripted model       414.70ms     4.58%\n",
      "2              scripted & quantized model       260.70ms    40.01%\n",
      "3  scripted & quantized & optimized model       215.87ms    50.33%\n",
      "4                              lite model       231.92ms    46.64%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({'Model': ['original model','scripted model', 'scripted & quantized model', 'scripted & quantized & optimized model', 'lite model']})\n",
    "df = pd.concat([df, pd.DataFrame([\n",
    "    [\"{:.2f}ms\".format(prof1.self_cpu_time_total/1000), \"0%\"],\n",
    "    [\"{:.2f}ms\".format(prof2.self_cpu_time_total/1000),\n",
    "     \"{:.2f}%\".format((prof1.self_cpu_time_total-prof2.self_cpu_time_total)/prof1.self_cpu_time_total*100)],\n",
    "    [\"{:.2f}ms\".format(prof3.self_cpu_time_total/1000),\n",
    "     \"{:.2f}%\".format((prof1.self_cpu_time_total-prof3.self_cpu_time_total)/prof1.self_cpu_time_total*100)],\n",
    "    [\"{:.2f}ms\".format(prof4.self_cpu_time_total/1000),\n",
    "     \"{:.2f}%\".format((prof1.self_cpu_time_total-prof4.self_cpu_time_total)/prof1.self_cpu_time_total*100)],\n",
    "    [\"{:.2f}ms\".format(prof5.self_cpu_time_total/1000),\n",
    "     \"{:.2f}%\".format((prof1.self_cpu_time_total-prof5.self_cpu_time_total)/prof1.self_cpu_time_total*100)]],\n",
    "    columns=['Inference Time', 'Reduction'])], axis=1)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94f565c-9ba5-4492-85ac-54ebc2738b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
