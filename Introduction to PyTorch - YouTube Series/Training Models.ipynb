{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMmJTzJYkS4Q6d0MZj1032y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Introduction\n","* 지난 시간 동안 우리는 다음 사항에 대해 시행함.\n","  + torch.nn 모듈의 신경망 레이어와 기능을 사용하여 모델 구축\n","  + 경사 기반 모델 훈련의 핵심인 자동화된 경사 계산의 메커니즘\n","  + TensorBoard를 사용하여 훈련 진행 상황 및 기타 활동 시각화\n","* 여기에서는 인벤토리에 몇 가지 새로운 도구를 추가해보겠음.\n","  + 데이터 세트 및 데이터 로더 추상화에 대해 알아보고, 훈련 루프 중에 모델에 데이터를 공급하는 프로세스를 쉽게 만드는 방법에 대해 알아봄.\n","  + 특정 손실 함수와 이를 언제 사용하는지 논의함.\n","  + 손실 함수의 결과에 따라 모델 가중치를 조정하는 알고리즘을 구현하는 PyTorch 최적화 프로그램을 살펴봄.\n","* 마지막으로, 이 모든 것을 하나로 모아 전체 PyTorch 훈련 루프가 실제로 작동하는 모습을 살펴봄."],"metadata":{"id":"Hc6x4j_vaAzh"}},{"cell_type":"markdown","source":["### Dataset and DataLoader\n","* Dataset 및 DataLoader 클래스는 스토리지에서 데이터를 가져와 훈련 루프에 일괄적으로 노출하는 프로세스를 캡슐화함.\n","* Dataset는 단일 데이터 인스턴스에 액세스하고 처리하는 일을 담당함.\n","* DataLoader는 데이터 세트에서 데이터 인스턴스를(자동으로 또는 사용자가 정의한 샘플러를 사용하여)가져와 일괄적으로 수집하고 훈련 루프에서 사용할 수 있도록 반환함.\n","* DataLoader는 포함된 데이터 유형에 관계없이 모든 종류의 데이터 세트에서 작동함.\n","* 이 튜토리얼에서는 TorchVision에서 제공하는 Fashion-MNIST 데이터 세트를 사용함.\n","* 우리는 torchvision.transforms.Normalize()를 사용하여 이미지 타일 콘텐츠의 분포를 0 중심으로 정규화하고 훈련 및 검증 데이터 분할 모두 다운로드함."],"metadata":{"id":"C0s4H0jBapGu"}},{"cell_type":"code","source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","# PyTorch TensorBoard support\n","from torch.utils.tensorboard import SummaryWriter\n","from datetime import datetime\n","\n","transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5,), (0.5))]\n",")\n","\n","# Create datasets for training & validation, download if necessary\n","training_set = torchvision.datasets.FashionMNIST('./data', train=True, transform=transform, download=True)\n","validation_set = torchvision.datasets.FashionMNIST('./data', train=False, transform=transform, download=True)\n","\n","# Create data loaders for our datasets; shuffle for training, not for validation\n","training_loader = torch.utils.data.DataLoader(training_set, batch_size=4, shuffle=True)\n","validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=4, shuffle=False)\n","\n","# Class labels\n","classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n","        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n","\n","# Report split sizes\n","print('Training set has {} instances'.format(len(training_set)))\n","print('Validation set has {} instances'.format(len(validation_set)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hGIh1U8mbhYH","executionInfo":{"status":"ok","timestamp":1710983464098,"user_tz":-540,"elapsed":21809,"user":{"displayName":"Jeongwon Lee","userId":"00025330246772348535"}},"outputId":"6f4726b2-dfcf-41a7-cc89-b6f1a69bac54"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Training set has 60000 instances\n","Validation set has 10000 instances\n"]}]},{"cell_type":"markdown","source":["* 언제나 그렇듯, 온전성 검사를 위해 데이터를 시각화해보겠음."],"metadata":{"id":"ZEYzkrFpcfsb"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Helper function for inline image display\n","def matplotlib_imshow(img, one_channel=False):\n","  if one_channel:\n","    img = img.mean(dim=0)\n","  img = img / 2 + 0.5 # unnormalize\n","  npimg = img.numpy()\n","  if one_channel:\n","    plt.imshow(npimg, cmap=\"Greys\")\n","  else:\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","\n","dataiter = iter(training_loader)\n","images, labels = next(dataiter)\n","\n","# Create a grid from the images and show them\n","img_grid = torchvision.utils.make_grid(images)\n","matplotlib_imshow(img_grid, one_channel=True)\n","print('  '.join(classes[labels[j]] for j in range(4)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":212},"id":"xzNgMhCHck65","executionInfo":{"status":"ok","timestamp":1710983464532,"user_tz":-540,"elapsed":436,"user":{"displayName":"Jeongwon Lee","userId":"00025330246772348535"}},"outputId":"2ec3c045-1624-4d24-9b73-bb3a8e394ad1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["T-shirt/top  Shirt  Sandal  Bag\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["### The Model\n","* 이 예에서 사용할 모델은 LeNet-5의 변형임.\n","* 이 시리즈의 이전 과정을 진행했다면 익숙할 것."],"metadata":{"id":"0olTnK-LdJsS"}},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# PyTorch models inherit from torch.nn.Module\n","class GarmentClassifier(nn.Module):\n","  def __init__(self):\n","    super(GarmentClassifier, self).__init__()\n","    self.conv1 = nn.Conv2d(1, 6, 5)\n","    self.pool = nn.MaxPool2d(2, 2)\n","    self.conv2 = nn.Conv2d(6, 16, 5)\n","    self.fc1 = nn.Linear(16 * 4 * 4, 120)\n","    self.fc2 = nn.Linear(120, 84)\n","    self.fc3 = nn.Linear(84, 10)\n","\n","  def forward(self, x):\n","    x = self.pool(F.relu(self.conv1(x)))\n","    x = self.pool(F.relu(self.conv2(x)))\n","    x = x.view(-1, 16 * 4 * 4)\n","    x = F.relu(self.fc1(x))\n","    x = F.relu(self.fc2(x))\n","    x = self.fc3(x)\n","    return x\n","\n","model = GarmentClassifier()"],"metadata":{"id":"uPjVyN_IeIJJ","executionInfo":{"status":"ok","timestamp":1710983464532,"user_tz":-540,"elapsed":4,"user":{"displayName":"Jeongwon Lee","userId":"00025330246772348535"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["### Loss Function\n","* 이 예에서는 교차 엔트로피 손실을 사용함.\n","* 시연을 위해 더미 출력 및 레이블 값의 배치를 생성하고 이를 손실 함수를 통해 실행한 후 결과를 검사하겠음."],"metadata":{"id":"1m3HMuEvex-P"}},{"cell_type":"code","source":["loss_fn = torch.nn.CrossEntropyLoss()\n","\n","# NB : Loss functions expect data in batches, so we're creating batches of 4\n","# Represents the model's confidence in each of the 10 classes for a given input\n","dummy_outputs = torch.rand(4, 10)\n","# Represents the correct class among the 10 being tested\n","dummy_labels = torch.tensor([1, 5, 3, 7])\n","\n","print(dummy_outputs)\n","print(dummy_labels)\n","\n","loss = loss_fn(dummy_outputs, dummy_labels)\n","print('Total loss for this batch: {}'.format(loss.item()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z4QIvsADfCTI","executionInfo":{"status":"ok","timestamp":1710983464532,"user_tz":-540,"elapsed":3,"user":{"displayName":"Jeongwon Lee","userId":"00025330246772348535"}},"outputId":"b139d19d-b4c7-4133-90f1-b6fd26e23769"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.3058, 0.4620, 0.8058, 0.9188, 0.0721, 0.3206, 0.4815, 0.7775, 0.9349,\n","         0.6641],\n","        [0.2958, 0.4890, 0.6584, 0.3886, 0.0575, 0.5723, 0.2529, 0.9757, 0.0984,\n","         0.0347],\n","        [0.5007, 0.5906, 0.0508, 0.3366, 0.7498, 0.7810, 0.5829, 0.3311, 0.8627,\n","         0.6344],\n","        [0.4660, 0.0909, 0.1756, 0.2788, 0.1820, 0.0980, 0.1620, 0.7324, 0.7044,\n","         0.4910]])\n","tensor([1, 5, 3, 7])\n","Total loss for this batch: 2.2692384719848633\n"]}]},{"cell_type":"markdown","source":["### Optimizer\n","* 이 예에서는 운동량을 사용하는 간단한 확률적 경사하강법을 사용함.\n","* 이 최적화 방식을 몇 가지 변형해 보는 것이 도움이 될 수 있음.\n","  + 학습률은 최적화 프로그램이 수행하는 단계의 크기를 결정함. 정확도와 수렴 시간 측면에서 학습 속도가 다르면 훈련 결과에 어떤 영향을 미치는지?\n","  + Momentum은 여러 단계에 걸쳐 가장 강한 기울기 방향으로 최적화 프로그램을 조금씩 움직임. 이 값을 변경하면 결과에 어떤 영향을 미치는지?\n","  + 평균 SGD, Adagrad 또는 Adam 과 같은 다양한 최적화 알고리즘을 사용해보기. 결과는 어떻게 다른지?"],"metadata":{"id":"CE21gbmafkvq"}},{"cell_type":"code","source":["# Optimizers specified in the torch.optim package\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"],"metadata":{"id":"DKxMsyKtgD1Q","executionInfo":{"status":"ok","timestamp":1710983464532,"user_tz":-540,"elapsed":3,"user":{"displayName":"Jeongwon Lee","userId":"00025330246772348535"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["### The Training Loop\n","* 아래에는 하나의 훈련 에포크를 수행하는 함수가 있음.\n","* DataLoader의 데이터를 열거하고 루프의 각 패스에서 다음을 수행함.\n","  + DataLoader에서 훈련 데이터 배치를 가져옴.\n","  + 옵티마이저의 기울기를 0으로 만듦.\n","  + 추론을 수행함. (즉, 입력 배치에 대한 모델에서 예측을 가져옴.)\n","  + 해당 예측 세트와 데이터세트의 라벨에 대한 손실을 계산함.\n","  + 학습 가중치에 대한 역방향 기울기를 계산함.\n","  + 최적화 프로그램에 하나의 학습 단계를 수행하도록 지시함. (즉, 우리가 선택한 최적화 알고리즘에 따라 이 배치에 대해 관찰된 기울기를 기반으로 모델의 학습 가중치를 조정함.)\n","  + 1000개 배치마다 손실을 보고함.\n","  + 마지막으로 검증 실행과 비교하기 위해 마지막 1000개 배치에 대한 평균 배치당 손실을 보고함."],"metadata":{"id":"V5B-e0H8gL_V"}},{"cell_type":"code","source":["def train_one_epoch(epoch_index, tb_writer):\n","    running_loss = 0.\n","    last_loss = 0.\n","\n","    # Here, we use enumerate(training_loader) instead of\n","    # iter(training_loader) so that we can track the batch\n","    # index and do some intra-epoch reporting\n","    for i, data in enumerate(training_loader):\n","        # Every data instance is an input + label pair\n","        inputs, labels = data\n","\n","        # Zero your gradients for every batch!\n","        optimizer.zero_grad()\n","\n","        # Make predictions for this batch\n","        outputs = model(inputs)\n","\n","        # Compute the loss and its gradients\n","        loss = loss_fn(outputs, labels)\n","        loss.backward()\n","\n","        # Adjust learning weights\n","        optimizer.step()\n","\n","        # Gather data and report\n","        running_loss += loss.item()\n","        if i % 1000 == 999:\n","            last_loss = running_loss / 1000 # loss per batch\n","            print('  batch {} loss: {}'.format(i + 1, last_loss))\n","            tb_x = epoch_index * len(training_loader) + i + 1\n","            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n","            running_loss = 0.\n","\n","    return last_loss"],"metadata":{"id":"hm-D64gGgyv4","executionInfo":{"status":"ok","timestamp":1710983464532,"user_tz":-540,"elapsed":2,"user":{"displayName":"Jeongwon Lee","userId":"00025330246772348535"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["### Per-Epoch Activity\n","* 에포크당 한 번씩 수행하고 싶은 몇 가지 작업이 있음.\n","  + 훈련에 사용되지 않은 데이터 세트에 대한 상대적 손실을 확인하여 검증을 수행하고 이를 보고함.\n","  + 모델 사본 저장함.\n","* 여기서는 TensorBoard에서 보고를 수행하겠음.\n","* TensorBoard를 시작하려면 명령줄로 이동하고 다른 브라우저 탭에서 열어야 함."],"metadata":{"id":"VvizPZbXiHvk"}},{"cell_type":"code","source":["# Initializing in a separate cell so we can easily add more epochs to the same run\n","timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n","writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n","epoch_number = 0\n","\n","EPOCHS = 5\n","\n","best_vloss = 1_000_000.\n","\n","for epoch in range(EPOCHS):\n","    print('EPOCH {}:'.format(epoch_number + 1))\n","\n","    # Make sure gradient tracking is on, and do a pass over the data\n","    model.train(True)\n","    avg_loss = train_one_epoch(epoch_number, writer)\n","\n","    # We don't need gradients on to do reporting\n","    model.train(False)\n","\n","    running_vloss = 0.0\n","    for i, vdata in enumerate(validation_loader):\n","        vinputs, vlabels = vdata\n","        voutputs = model(vinputs)\n","        vloss = loss_fn(voutputs, vlabels)\n","        running_vloss += vloss\n","\n","    avg_vloss = running_vloss / (i + 1)\n","    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n","\n","    # Log the running loss averaged per batch\n","    # for both training and validation\n","    writer.add_scalars('Training vs. Validation Loss',\n","                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n","                    epoch_number + 1)\n","    writer.flush()\n","\n","    # Track best performance, and save the model's state\n","    if avg_vloss < best_vloss:\n","        best_vloss = avg_vloss\n","        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n","        torch.save(model.state_dict(), model_path)\n","\n","    epoch_number += 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dm5LvwnfiWVs","executionInfo":{"status":"ok","timestamp":1710983987429,"user_tz":-540,"elapsed":522899,"user":{"displayName":"Jeongwon Lee","userId":"00025330246772348535"}},"outputId":"e8d1418f-732b-43a3-92e2-bcb2b39475d5"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["EPOCH 1:\n","  batch 1000 loss: 1.9312215489149094\n","  batch 2000 loss: 0.9033946783691644\n","  batch 3000 loss: 0.726324409853667\n","  batch 4000 loss: 0.6312425659075379\n","  batch 5000 loss: 0.5966652128899004\n","  batch 6000 loss: 0.5831051479429007\n","  batch 7000 loss: 0.5205938018013258\n","  batch 8000 loss: 0.5188731760135852\n","  batch 9000 loss: 0.49396122266026216\n","  batch 10000 loss: 0.47945983507717027\n","  batch 11000 loss: 0.4487224697736092\n","  batch 12000 loss: 0.4554383456071373\n","  batch 13000 loss: 0.44148206407006363\n","  batch 14000 loss: 0.45414059729955625\n","  batch 15000 loss: 0.41775117725267774\n","LOSS train 0.41775117725267774 valid 0.48257148265838623\n","EPOCH 2:\n","  batch 1000 loss: 0.4117402998544858\n","  batch 2000 loss: 0.3908915705666732\n","  batch 3000 loss: 0.39003376235981707\n","  batch 4000 loss: 0.3972300202934857\n","  batch 5000 loss: 0.40435461342913914\n","  batch 6000 loss: 0.37797154280892575\n","  batch 7000 loss: 0.3752895968472003\n","  batch 8000 loss: 0.3797078998180223\n","  batch 9000 loss: 0.36683227308324423\n","  batch 10000 loss: 0.3850959053641709\n","  batch 11000 loss: 0.36157990380481353\n","  batch 12000 loss: 0.3683868954277132\n","  batch 13000 loss: 0.37272336502277176\n","  batch 14000 loss: 0.3527720749675646\n","  batch 15000 loss: 0.3580705825637997\n","LOSS train 0.3580705825637997 valid 0.3755894899368286\n","EPOCH 3:\n","  batch 1000 loss: 0.32961123488364685\n","  batch 2000 loss: 0.3348501907429745\n","  batch 3000 loss: 0.3376991853000945\n","  batch 4000 loss: 0.32447480344340146\n","  batch 5000 loss: 0.34652775280247444\n","  batch 6000 loss: 0.3541251123083639\n","  batch 7000 loss: 0.34841086430440193\n","  batch 8000 loss: 0.3227690164596788\n","  batch 9000 loss: 0.33437809291598386\n","  batch 10000 loss: 0.3189829195872735\n","  batch 11000 loss: 0.34078297404614566\n","  batch 12000 loss: 0.3325707484938903\n","  batch 13000 loss: 0.33581357228299746\n","  batch 14000 loss: 0.3220389833627851\n","  batch 15000 loss: 0.3441893495469558\n","LOSS train 0.3441893495469558 valid 0.34636127948760986\n","EPOCH 4:\n","  batch 1000 loss: 0.3054820037749596\n","  batch 2000 loss: 0.31390195040230173\n","  batch 3000 loss: 0.30356209178114657\n","  batch 4000 loss: 0.30117878090809974\n","  batch 5000 loss: 0.3212101008423342\n","  batch 6000 loss: 0.3144053609295224\n","  batch 7000 loss: 0.3011448514094227\n","  batch 8000 loss: 0.3069751728402116\n","  batch 9000 loss: 0.31308043445039946\n","  batch 10000 loss: 0.30622246629755684\n","  batch 11000 loss: 0.30848186026561963\n","  batch 12000 loss: 0.3206501792287454\n","  batch 13000 loss: 0.2999380637141076\n","  batch 14000 loss: 0.31696498966043873\n","  batch 15000 loss: 0.3061057101089391\n","LOSS train 0.3061057101089391 valid 0.33759796619415283\n","EPOCH 5:\n","  batch 1000 loss: 0.2956920678089919\n","  batch 2000 loss: 0.2925336367537966\n","  batch 3000 loss: 0.2726288066037232\n","  batch 4000 loss: 0.2914211773849456\n","  batch 5000 loss: 0.2989463410249864\n","  batch 6000 loss: 0.2895289061016956\n","  batch 7000 loss: 0.3108224436817982\n","  batch 8000 loss: 0.28852869651466606\n","  batch 9000 loss: 0.27830402670689547\n","  batch 10000 loss: 0.30499202631616207\n","  batch 11000 loss: 0.2976271699199797\n","  batch 12000 loss: 0.29969429060305264\n","  batch 13000 loss: 0.28929203847142343\n","  batch 14000 loss: 0.29186666753549073\n","  batch 15000 loss: 0.29556846578979956\n","LOSS train 0.29556846578979956 valid 0.3203524053096771\n"]}]},{"cell_type":"markdown","source":["* 저장된 버전의 모델을 로드하려면"],"metadata":{"id":"41T-ZLqbjrCI"}},{"cell_type":"code","source":["# saved_model = GarmentClassifier()\n","# saved_model.load_state_dict(torch.load(PATH))"],"metadata":{"id":"a7rxZN1Tj9ig","executionInfo":{"status":"ok","timestamp":1710984115508,"user_tz":-540,"elapsed":326,"user":{"displayName":"Jeongwon Lee","userId":"00025330246772348535"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["* 모델을 로드하고 나면 추가 교육, 추론, 분석 등 필요한 모든 작업을 수행할 수 있음.\n","* 모델에 모델 구조에 영향을 미치는 생성자 매개변수가 있는 경우 해당 매개변수를 제공하고 모델이 저장된 상태와 동일하게 모델을 구성해야 함."],"metadata":{"id":"PP7k8CUuj_Ui"}},{"cell_type":"code","source":[],"metadata":{"id":"-oP5BTPzkGO8"},"execution_count":null,"outputs":[]}]}