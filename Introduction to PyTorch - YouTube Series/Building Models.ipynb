{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP9WMMxvWcH71lk0mzsOd52"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["### torch.nn.Module 그리고 torch.nn Parameter"],"metadata":{"id":"EL9I_z_PWtVI"}},{"cell_type":"markdown","source":["* Parameter를 제외하고 torch.nn.Module의 하위 클래스.\n","* 이는 PyTorch 모델 및 해당 구성 요소와 관련된 동작을 캡슐화하기 위한 PyTorch 기본 클래스임."],"metadata":{"id":"m2Q4oALcXIIb"}},{"cell_type":"markdown","source":["* torch.nn.Module의 중요한 동작 중 하나는 매개변수를 등록하는 것.\n","* 특정 Module 하위 클래스가 학습 가중치를 가지고 있는 경우, 이러한 가중치는 torch.nn.Parameter의 인스턴스로 표현됨.\n","* Parameter 클래스는 torch.Tensor의 하위 클래스로, 특별한 동작을 가지고 있음.\n","* Module의 속성으로 할당될 때 해당 모듈의 매개변수 목록에 추가됨.\n","* 이러한 매개변수는 Module 클래스의 parameters() 메서드를 통해 액세스할 수 있음.\n"],"metadata":{"id":"tFoV-lVVXwJT"}},{"cell_type":"markdown","source":["* 간단한 예로, 두 개의 선형 레이어와 활성화 함수가 있는 매우 간단한 모델이 있음.\n","* 이 모델의 인스턴스를 만들고 그 매개변수에 대해 보고를 요청할 것."],"metadata":{"id":"DxNFaG7EYriJ"}},{"cell_type":"code","source":["import torch\n","\n","class TinyModel(torch.nn.Module):\n","\n","    def __init__(self):\n","        super(TinyModel, self).__init__()\n","\n","        self.linear1 = torch.nn.Linear(100, 200)\n","        self.activation = torch.nn.ReLU()\n","        self.linear2 = torch.nn.Linear(200, 10)\n","        self.softmax = torch.nn.Softmax()\n","\n","    def forward(self, x):\n","        x = self.linear1(x)\n","        x = self.activation(x)\n","        x = self.linear2(x)\n","        x = self.softmax(x)\n","        return x\n","\n","tinymodel = TinyModel()\n","\n","print('The model:')\n","print(tinymodel)\n","\n","print('\\n\\nJust one layer:')\n","print(tinymodel.linear2)\n","\n","print('\\n\\nModel params:')\n","for param in tinymodel.parameters():\n","    print(param)\n","\n","print('\\n\\nLayer params:')\n","for param in tinymodel.linear2.parameters():\n","    print(param)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cklAPXqLYspX","executionInfo":{"status":"ok","timestamp":1710937680280,"user_tz":-540,"elapsed":4357,"user":{"displayName":"Jeongwon Lee","userId":"00025330246772348535"}},"outputId":"e0e6de70-b35b-4161-a4c4-186832db0a01"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The model:\n","TinyModel(\n","  (linear1): Linear(in_features=100, out_features=200, bias=True)\n","  (activation): ReLU()\n","  (linear2): Linear(in_features=200, out_features=10, bias=True)\n","  (softmax): Softmax(dim=None)\n",")\n","\n","\n","Just one layer:\n","Linear(in_features=200, out_features=10, bias=True)\n","\n","\n","Model params:\n","Parameter containing:\n","tensor([[-0.0761,  0.0504, -0.0850,  ...,  0.0445,  0.0746,  0.0464],\n","        [ 0.0094, -0.0644,  0.0416,  ..., -0.0369, -0.0182, -0.0972],\n","        [-0.0099,  0.0432,  0.0248,  ...,  0.0085, -0.0284, -0.0254],\n","        ...,\n","        [ 0.0192,  0.0655, -0.0498,  ...,  0.0789,  0.0757,  0.0232],\n","        [-0.0903, -0.0237,  0.0134,  ..., -0.0915,  0.0524, -0.0818],\n","        [ 0.0074, -0.0654,  0.0797,  ...,  0.0417,  0.0788,  0.0180]],\n","       requires_grad=True)\n","Parameter containing:\n","tensor([ 0.0861,  0.0838,  0.0176,  0.0172,  0.0621,  0.0358, -0.0537, -0.0049,\n","         0.0286,  0.0464,  0.0868, -0.0407, -0.0046,  0.0711,  0.0307, -0.0494,\n","         0.0094,  0.0830,  0.0481,  0.0363, -0.0042,  0.0126, -0.0645, -0.0677,\n","         0.0535,  0.0461, -0.0016, -0.0364,  0.0765,  0.0250, -0.0768,  0.0972,\n","        -0.0198,  0.0675, -0.0290, -0.0175,  0.0264,  0.0135, -0.0318,  0.0083,\n","        -0.0067, -0.0064, -0.0693,  0.0202, -0.0085,  0.0295,  0.0189, -0.0274,\n","         0.0810,  0.0503, -0.0626,  0.0857,  0.0674, -0.0982,  0.0866,  0.0370,\n","        -0.0507, -0.0184,  0.0447,  0.0763, -0.0018,  0.0131,  0.0653,  0.0943,\n","        -0.0623,  0.0899,  0.0503, -0.0400, -0.0874, -0.0598,  0.0848, -0.0967,\n","        -0.0589,  0.0693, -0.0587, -0.0232,  0.0474,  0.0213, -0.0481, -0.0992,\n","        -0.0757,  0.0129, -0.0700,  0.0104, -0.0985, -0.0036, -0.0605, -0.0232,\n","        -0.0870,  0.0260,  0.0445,  0.0558, -0.0568,  0.0337,  0.0343, -0.0905,\n","         0.0447,  0.0775,  0.0445,  0.0056, -0.0344,  0.0462,  0.0599,  0.0821,\n","        -0.0069, -0.0159,  0.0881, -0.0384, -0.0083,  0.0376,  0.0367,  0.0245,\n","        -0.0779, -0.0694, -0.0940,  0.0307,  0.0013, -0.0586, -0.0549,  0.0676,\n","         0.0473, -0.0844, -0.0207, -0.0919,  0.0623,  0.0116,  0.0573,  0.0483,\n","        -0.0455,  0.0946, -0.0127,  0.0130, -0.0589, -0.0077,  0.0439,  0.0221,\n","        -0.0007, -0.0681, -0.0984, -0.0223,  0.0254, -0.0253, -0.0246, -0.0741,\n","         0.0463,  0.0373,  0.0392, -0.0209, -0.0166, -0.0857, -0.0214,  0.0192,\n","         0.0113,  0.0420,  0.0194, -0.0825, -0.0964, -0.0403, -0.0069, -0.0231,\n","         0.0879,  0.0496, -0.0003,  0.0683, -0.0077, -0.0807,  0.0325,  0.0553,\n","         0.0986, -0.0676, -0.0106, -0.0931,  0.0947, -0.0879, -0.0862,  0.0560,\n","         0.0991, -0.0054,  0.0513, -0.0138,  0.0418, -0.0627, -0.0966,  0.0049,\n","        -0.0850, -0.0839,  0.0982, -0.0519, -0.0953,  0.0372,  0.0346,  0.0203,\n","        -0.0062, -0.0512, -0.0141,  0.0473,  0.0861, -0.0303,  0.0838, -0.0512],\n","       requires_grad=True)\n","Parameter containing:\n","tensor([[-0.0448, -0.0125,  0.0159,  ..., -0.0670, -0.0654,  0.0114],\n","        [ 0.0322, -0.0333, -0.0240,  ...,  0.0470,  0.0638, -0.0165],\n","        [-0.0561, -0.0425, -0.0636,  ..., -0.0366, -0.0450, -0.0146],\n","        ...,\n","        [ 0.0107, -0.0522,  0.0596,  ...,  0.0258,  0.0087, -0.0081],\n","        [ 0.0681, -0.0231,  0.0087,  ...,  0.0588, -0.0337, -0.0292],\n","        [-0.0208, -0.0146, -0.0515,  ..., -0.0297, -0.0043, -0.0407]],\n","       requires_grad=True)\n","Parameter containing:\n","tensor([-0.0556,  0.0629,  0.0134,  0.0292,  0.0210, -0.0514,  0.0387,  0.0035,\n","         0.0673, -0.0686], requires_grad=True)\n","\n","\n","Layer params:\n","Parameter containing:\n","tensor([[-0.0448, -0.0125,  0.0159,  ..., -0.0670, -0.0654,  0.0114],\n","        [ 0.0322, -0.0333, -0.0240,  ...,  0.0470,  0.0638, -0.0165],\n","        [-0.0561, -0.0425, -0.0636,  ..., -0.0366, -0.0450, -0.0146],\n","        ...,\n","        [ 0.0107, -0.0522,  0.0596,  ...,  0.0258,  0.0087, -0.0081],\n","        [ 0.0681, -0.0231,  0.0087,  ...,  0.0588, -0.0337, -0.0292],\n","        [-0.0208, -0.0146, -0.0515,  ..., -0.0297, -0.0043, -0.0407]],\n","       requires_grad=True)\n","Parameter containing:\n","tensor([-0.0556,  0.0629,  0.0134,  0.0292,  0.0210, -0.0514,  0.0387,  0.0035,\n","         0.0673, -0.0686], requires_grad=True)\n"]}]},{"cell_type":"markdown","source":["* 이것은 PyTorch 모델의 기본 구조를 보여줌.\n","* 모델의 레이어 및 다른 구성 요소를 정의하는 init() 메서드가 있고, 계산이 수행되는 forward() 메서드가 있음.\n","* 모델 또는 그 하위 모듈 중 하나를 출력하여 구조에 대해 알아볼 수 있음."],"metadata":{"id":"zymHx657cUqC"}},{"cell_type":"markdown","source":["### Common Layer Types\n","### Linear Layers\n","* 가장 기본적인 유형의 신경망 레이어는 선형 또는 완전히 연결된 레이어임.\n","* 이는 레이어의 가중치에 의해 지정된 정도로 각 입력이 레이어의 모든 출력에 영향을 미치는 레이어임.\n","* 모델이 m 개의 입력과 n 개의 출력을 가지는 경우, 가중치는 m x n 행렬이 됨.\n"],"metadata":{"id":"5WqEB5wYa_Lg"}},{"cell_type":"code","source":["lin = torch.nn.Linear(3, 2)\n","x = torch.rand(1, 3)\n","print('Input:')\n","print(x)\n","\n","print('\\n\\nWeight and Bias parameters:')\n","for param in lin.parameters():\n","  print(param)\n","\n","y = lin(x)\n","print('\\n\\nOutput:')\n","print(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kvj1Uvapcune","executionInfo":{"status":"ok","timestamp":1710937680929,"user_tz":-540,"elapsed":650,"user":{"displayName":"Jeongwon Lee","userId":"00025330246772348535"}},"outputId":"20c89ab8-bbc7-4c82-e47d-2cc2679aceb8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input:\n","tensor([[0.4444, 0.7102, 0.5446]])\n","\n","\n","Weight and Bias parameters:\n","Parameter containing:\n","tensor([[-0.5363,  0.4116,  0.5762],\n","        [ 0.0862, -0.3749, -0.1343]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.1639, -0.3172], requires_grad=True)\n","\n","\n","Output:\n","tensor([[ 0.5317, -0.6183]], grad_fn=<AddmmBackward0>)\n"]}]},{"cell_type":"markdown","source":["* 만약 선형 레이어의 가중치로 x의 행렬 곱셈을 수행하고 편향을 더한다면, 출력 벡터 y를 얻게 될 것.\n","* 다른 중요한 기능 하나를 더 보자면, 우리가 lin.weight로 레이어의 가중치를 확인했을 때, 그것은 자신을 Paramenter(텐서의 하위 클래스)로 보고하고 autograd로 그래디언트를 추적하고 있을음 알림.\n","* 이것은 tensor와는 달리 Parameter의 기본 동작임."],"metadata":{"id":"Qs9_iwNUdYT2"}},{"cell_type":"markdown","source":["* 선형 레이어는 딥러닝 모델에서 널리 사용됨.\n","* 가장 흔하게 볼 수 있는 곳 중 하나는 분류기 모델임.\n","* 분류기 모델에서는 보통 끝 부분에 하나 이상의 선형 레이어가 있으며, 마지막 레이어는 분류기 처리하는 클래스의 수인 n개의 출력을 가짐."],"metadata":{"id":"sYcpviqseLhA"}},{"cell_type":"markdown","source":["### Convolution Layer\n","* 합성곱 레이어는 공간적 상관 관계가 높은 데이터를 처리하기 위해 만들어짐.\n","* 컴퓨터 비전에서 매우 일반적으로 사용되며, 여기에서 특성의 밀집된 그룹을 감지하고 더 높은 수준의 특성으로 구성함.\n","* 이러한 레이어는 다른 맥락에서도 나타남.\n","* 예를 들어, NLP(Natural Language Processing) 응용 프로그램에서는 단어의 즉각적인 컨텍스트(즉, 시퀀스 내에서 근처에 있는 다른 단어)가 문장의 의미에 영향을 미칠 수 있음.\n","* 이전 비디오에서 LeNet5에서 합성곱 레이어가 작동하는 것을 확인함."],"metadata":{"id":"ikwHVqC-eT2W"}},{"cell_type":"code","source":["import torch.functional as F\n","\n","class LeNet(torch.nn.Module):\n","\n","  def __init__(self):\n","    super(LeNet, self).__init__()\n","    # 1 input image channel (black and white), 6 output channels, 5 x 5 square convolution\n","    # kernel\n","    self.conv1 = torch.nn.Conv2d(1, 6, 5)\n","    self.conv2 = torch.nn.Conv2d(6, 16, 3)\n","    # an affine operation: y = Wx + b\n","    self.fc1 = torch.nn.Linear(16 * 6 * 6, 120) # 6 x 6 from image dimension\n","    self.fc2 = torch.nn.Linear(120, 84)\n","    self.fc3 = torch.nn.Linear(84, 10)\n","\n","  def forward(self, x):\n","    # Max pooling over a (2, 2) window\n","    x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n","    # If the size is a square you can only specify a single number\n","    x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n","    x = x.view(-1, self.num_flat_features(x))\n","    x = F.relu(self.fc1(x))\n","    x = F.relu(self.fc2(x))\n","    x = self.fc3(x)\n","    return x\n","\n","  def num_flat_features(self, x):\n","    size = x.size()[1:] # all dimensions except the batch dimension\n","    num_features = 1\n","    for s in size:\n","      num_features *= s\n","    return num_features"],"metadata":{"id":"joAOUH6ne-Wb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 이 모델의 컨볼루션 레이어에서 일어나는 과정을 살펴보겠음."],"metadata":{"id":"IrwxPN5whcNT"}},{"cell_type":"markdown","source":["* 우선 conv1 부터 시작하겠음.\n","  + LeNet5 는 1 x 32 x 32 흑백 이미지를 입력으로 받음.\n","  +  컨볼루션 레이어의 생성자에 대한 **첫 번째 인자는 입력 채널의 수**.\n","  + 여기서는 1임.\n","  + 만약 3개의 컬러 채널을 다루도록 구성한다면 이 값은 3이 될 것.\n","  + 컨볼루션 레이어는 이미지를 스캔하면서 인식하는 패턴을 찾는 창처럼 작동함.\n","  + 이러한 패턴을 특징이라고 하며, 컨볼루션 레이어의 두 번째 인자는 학습할 특징의 수임.\n","  + 여기서는 레이어가 6개의 특징을 학습하도록 설정함.\n","  + 위에서 컨볼루션 레이어를 창에 비유했지만, 이 창의 크기는 얼마일까요?\n","  + 세 번째 인자는 창 또는 커널 크기임.\n","  + 여기서 \"5\"는 5 x 5 커널을 선택했다는 것을 의미함. (만약 높이와 너비가 다른 커널을 원한다면 이 인자에 튜플을 지정할 수 있음.)\n"],"metadata":{"id":"wdrZ1HFjq-VJ"}},{"cell_type":"markdown","source":["* 컨볼루션 레이어의 출력은 활성화 맵.\n","* 입력 텐서에서 특징의 존재를 나타내는 공간적 표현.\n","* conv1은 출력 텐서를 6x28x28로 제공할 것.\n","* 여기서 6은 특징의 수, 28은 맵의 높이와 너비. (28은 32픽셀 행을 스캔할 때 5픽셀 창으로 스캔하는 경우 유효한 위치가 28개만 있기 때문에 나옴.)"],"metadata":{"id":"QQKi9EjnrJpQ"}},{"cell_type":"markdown","source":["* 다음 컨볼루션 레이어인 conv2는 6개의 입력 채널을 기대하며 (첫 번째 레이어에서 찾은 6개의 특징에 해당.), 16개의 출력 채널과 3 x 3 커널을 가짐.\n","* 이는 16 x 12 x 12 활성화 맵을 출력하며, 다시 한 번 최대 풀링 레이어에 의해 16 x 6 x 6 로 줄어듦.\n","* 이 출력을 선형 레이어에서 소비할 수 있도록 16 x 6 x 6 = 576 요소로 재구성됨."],"metadata":{"id":"QB0JYSIlrSTV"}},{"cell_type":"markdown","source":["* 컨볼루션 레이어는 1D, 2D 및 3D 텐서를 다루기 위한 것.\n","* 또한 입력의 스트라이드 길이(예 : 매 2 번째 또는 매 3 번째 위치만 스캔), 패딩(입력의 가장자리까지 스캔할 수 있또록)과 같은 많은 추가 인자가 있음."],"metadata":{"id":"tbH-XEqcsYnp"}},{"cell_type":"markdown","source":["### 순환 레이어\n","* 순환 신경망 (또는 RNN) 은 순차적 데이터에 사용됨.\n","* 과학 기기의 시계열 측정값부터 자연어 문장, DNA 염기까지 다양한 데이터 형태를 다룸.\n","* RNN은 현재까지 본 시퀀스에 대한 일종의 메모리 역할을 하는 숨겨진 상태를 유지함으로써 이를 수행함.\n","* 순환 신경망 레이어의 내부 구조 또는 그 변형인 LSTM (장단기 기억) 및 GRU (게이트 순환 유닛)은 다소 복잡하며 이 비디오의 범위를 벗어나지만, 우리는 LSTM 기반의 품사 태거(단어가 명사, 동사 등인지를 알려주는 분류기의 한 유형)를 통해 어떻게 작동하는지 보여줌."],"metadata":{"id":"6f_x8201ssHR"}},{"cell_type":"code","source":["class LSTMTagger(torch.nn.Module):\n","\n","  def __init__(self, embedding_dim, hidden_dim, vocab_size, target_size):\n","    super(LSTMTagger, self).__init__()\n","    self.hidden_dim = hidden_dim\n","\n","    self.word_embeddings = torch.nn.Embedding(vocab_size, embedding_dim)\n","\n","    # The LSTM takes word embeddings as inputs, and outputs hidden states\n","    # With dimensionality hidden_dim\n","    self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim)\n","\n","    # The linear layer that maps from hidden state space to tag space\n","    self.hidden2tag = torch.nn.Linear(hidden_dim, target_size)\n","\n","  def forward(self, sentence):\n","    embeds = self.word_embeddings(sentence)\n","    lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n","    target_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n","    target_scores = F.log_softmax(target_space, dim=1)\n","    return target_scores"],"metadata":{"id":"AexlmGnQsnko"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 생성자에는 네 가지 인수가 있음.\n","  + vocab_size 는 입력 어휘의 단어 수.\n","  + 각 단어는 vocab_size 차원 공간에서의 원핫 벡터(또는 단위 벡터)\n","  + target_size는 출력 집합의 태그 수.\n","  + embedding_dim은 어휘 인베딩 공간의 크기.\n","  + 임베딩은 어휘를 저차원 공간에 매핑하는데, 이 공간에서 의미한 유사한 단어들은 공간 상에서 서로 가까이 위치함.\n","  + hidden_dim 은 LSTM의 메모리 크기."],"metadata":{"id":"4bsvSEy8txUR"}},{"cell_type":"markdown","source":["* 입력은 단어가 원핫 벡터의 인덱스로 표현된 문장임.\n","* 임베딩 레이어는 이를 embedding_dim 차원의 공간으로 매핑함.\n","* LSTM은 이러한 임베딩 시퀀스를 가져와 이를 반복하여 hidden_dim 길이의 출력 벡터를 생성함.\n","* 최종 선형 레이어는 분류기 역할을 하며, 최종 레이어의 출력에 log_softmax()를 적용하여 주어진 단어가 주어진 태그로 매핑될 확률을 정규화된 추정 확률 집합으로 변환함."],"metadata":{"id":"Owt6tdlaukYE"}},{"cell_type":"markdown","source":["### Transformer\n","* 트랜스포머는 BERT와 같은 모델을 통해 자연어 처리의 최첨단 기술로 등장하여 다양한 용도로 사용되는 네트워크임.\n","* PyTorch에는 트랜스포머 모델의 전반적인 매개변수를 정의할 수 있는 Transformer 클래스가 있음.\n","* 이 클래스는 어텐션 헤드의 수, 인코더 및 디코더 레이어의 수, 드롭아웃 및 활성화 함수 등을 설정할 수 있음. (적절한 매개변수를 사용하여 이 클래스에서 BERT 모델을 빌드할 수 있음.)\n","* torch.nn.Transformer 클래스에는 개별 구성 요소 (TransformerEncoder, TransformerDecoder)와 하위 구성 요소 (TransformerEncoderLayer, TransformerDecoderLayer)를 캡슐화하는 클래스도 있음."],"metadata":{"id":"_gRHMxzdu5DN"}},{"cell_type":"markdown","source":["### Other Layers and Functions\n","### Data Manipulation Layers\n","* 최대 풀링 (그리고 그와 쌍을 이루는 최소 풀링)은 텐서를 셀을 결합하고, 입력 셀의 최댓값을 출력 셀에 할당하여 텐서를 줄임."],"metadata":{"id":"nKx9UkI5vf4U"}},{"cell_type":"code","source":["my_tensor = torch.rand(1, 6, 6)\n","print(my_tensor)\n","\n","maxpool_layer = torch.nn.MaxPool2d(3)\n","print(maxpool_layer(my_tensor))"],"metadata":{"id":"vKpDmI0lvrpI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710937690937,"user_tz":-540,"elapsed":2,"user":{"displayName":"Jeongwon Lee","userId":"00025330246772348535"}},"outputId":"66923033-59bc-4bda-958c-5f412006deb0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[0.1669, 0.6670, 0.0691, 0.9314, 0.9236, 0.7897],\n","         [0.4204, 0.4785, 0.7635, 0.7198, 0.7221, 0.9211],\n","         [0.1150, 0.0205, 0.4211, 0.8410, 0.1107, 0.9597],\n","         [0.1470, 0.0499, 0.3237, 0.0457, 0.6914, 0.3067],\n","         [0.2798, 0.2738, 0.2144, 0.1522, 0.9379, 0.7042],\n","         [0.5752, 0.1813, 0.7238, 0.3005, 0.4858, 0.9441]]])\n","tensor([[[0.7635, 0.9597],\n","         [0.7238, 0.9441]]])\n"]}]},{"cell_type":"markdown","source":["* 위의 값을 자세히 살펴보면 maxpooled 출력의 각 값이 6 x 6 입력의 각 사분면의 최대값임을 알 수 있음."],"metadata":{"id":"lM5U1M4h1YeN"}},{"cell_type":"markdown","source":["* 정규화 레이어는 한 레이어의 출력을 다른 레이어에 공급하기 전에 다시 중앙에 배치하고 정규화함.\n","* 중간 텐서를 중앙에 배치하고 크기를 조정하면 경사도가 폭발하거나 사라지지 않고 더 높은 학습률을 사용할 수 있는 등 여러 가지 유익한 효과가 있음."],"metadata":{"id":"fh5Rr_4I1U0N"}},{"cell_type":"code","source":["my_tensor = torch.rand(1, 4, 4) * 20 + 5\n","print(my_tensor)\n","\n","print(my_tensor.mean())\n","\n","norm_layer = torch.nn.BatchNorm1d(4)\n","normed_tensor = norm_layer(my_tensor)\n","print(normed_tensor)\n","\n","print(normed_tensor.mean())"],"metadata":{"id":"gbIB-6Hl1X_s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710937829797,"user_tz":-540,"elapsed":3,"user":{"displayName":"Jeongwon Lee","userId":"00025330246772348535"}},"outputId":"47fb7046-8d1c-4dfd-92c0-efa4a841e7c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[15.7795,  7.6450, 22.3092, 23.8927],\n","         [18.5447, 23.5124,  6.5881,  9.8195],\n","         [19.4506, 13.2722, 16.2240, 17.1098],\n","         [ 7.9119, 14.2600, 18.5712,  5.3012]]])\n","tensor(15.0120)\n","tensor([[[-0.2541, -1.5243,  0.7656,  1.0128],\n","         [ 0.5823,  1.3187, -1.1900, -0.7110],\n","         [ 1.3275, -1.4656, -0.1312,  0.2693],\n","         [-0.6897,  0.5268,  1.3530, -1.1900]]],\n","       grad_fn=<NativeBatchNormBackward0>)\n","tensor(-1.0431e-07, grad_fn=<MeanBackward0>)\n"]}]},{"cell_type":"markdown","source":["* 위의 셀을 실행하여 입력 텐서에 큰 배율 인수와 오프셋을 추가함.\n","* 입력 텐서는 15 근처 어딘가에 표시되어야 함.\n","* 정규화 레이어를 통해 실행한 후에는 값이 더 작고 0을 중심으로 그룹화되어 있음을 알 수 있음.\n","* 실제로 평균은 매우 작아야 함. ( > 1e-8)"],"metadata":{"id":"SmTDbJ7P125V"}},{"cell_type":"markdown","source":["* 이는 많은 활성화 함수가 0 근처에서 가장 강한 기울기를 갖기 때문에 유용하지만 때로는 입력에 대해 기울기가 사라지거나 폭발하여 0에서 멀리 떨어져 있기 때문에 유용함.\n","* 가장 가파른 경사 영역을 중심으로 데이터를 유지하면 더 빠르고 더 나은 학습과 더 높은 실행 가능한 학습 속도를 의미하는 경향이 있음."],"metadata":{"id":"pj2Jfdfn8jV7"}},{"cell_type":"markdown","source":["* 드롭아웃 레이어는 모델에서 희소 표현을 장려하는 도구.\n","* 즉, 더 적은 데이터로 추론을 수행하도록 유도하는 도구."],"metadata":{"id":"txJREA3d8913"}},{"cell_type":"markdown","source":["* 드롭아웃 레이어는 학습 중에 입력 텐서의 일부를 무작위로 설정하여 작동함.\n","* 드롭아웃 레이어는 추론을 위해 항상 꺼져 있음.\n","* 이렇게 하면 모델이 마스크되거나 축소된 데이터 세트에 대해 학습하게 됨."],"metadata":{"id":"Ur8bO9Of9CCy"}},{"cell_type":"code","source":["my_tensor = torch.rand(1, 4, 4)\n","\n","dropout = torch.nn.Dropout(p=0.4)\n","print(dropout(my_tensor))\n","print(dropout(my_tensor))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GuwiRgGj9Idn","executionInfo":{"status":"ok","timestamp":1710939769681,"user_tz":-540,"elapsed":488,"user":{"displayName":"Jeongwon Lee","userId":"00025330246772348535"}},"outputId":"1dc61fb8-118f-4762-c718-fc28c9a6d84e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[0.0000, 0.3696, 0.0000, 0.0000],\n","         [1.5895, 0.9548, 0.0000, 0.0000],\n","         [0.0000, 0.0000, 1.2475, 0.6377],\n","         [0.0000, 0.2069, 0.0000, 1.5246]]])\n","tensor([[[0.6939, 0.0000, 0.0000, 0.0000],\n","         [1.5895, 0.9548, 0.5724, 1.3018],\n","         [0.4830, 0.0000, 0.0000, 0.0000],\n","         [1.3501, 0.2069, 0.0000, 0.0000]]])\n"]}]},{"cell_type":"markdown","source":["* 위에서 샘플 텐서에 대한 드롭아웃 효과를 볼 수 있음.\n","* 선택적 p 인수를 사용하여 개별 가중치가 떨어질 확률을 설정할 수 있음.\n","* 그렇지 않으면 기본값은 0.5임."],"metadata":{"id":"hqIMEExz9QcH"}},{"cell_type":"markdown","source":["### Activation Function\n","* 활성화 기능을 통해 딥러닝이 가능해짐.\n","* 신경망은 실제로 수학 함수를 시뮬레이션하는 (많은 매개변수가 있는) 프로그램임.\n","* 우리가 한 모든 것이 레이어 가중치별로 여러 텐서를 반복적으로 수행하는 것뿐이었다면 선형 함수만 시뮬레이션할 수 있었음.\n","* 또한, 전체 네트워크가 단일 행렬 곱셈으로 축소될 수 있으므로 많은 레이어를 갖는 것은 의미가 없음.\n","* 레이어 사이에 비선형 함수를 삽입하면 딥러닝 모델이 선형 함수가 아닌 모든 함수를 시뮬레이션할 수 있음."],"metadata":{"id":"vv0T2TyE9Xx0"}},{"cell_type":"markdown","source":["* torch.nn.Module 은 ReLU 및 그 변형인 Tanh, Hardtanh, sigmoid 등을 포함한 모든 주요 활성화 함수를 캡슐화하는 객체가 있음.\n","* 또한 모델의 출력 단계에서 가장 유용한 Softmax 와 같은 다른 기능도 포함되어 있음."],"metadata":{"id":"xezDQFLg9tfk"}},{"cell_type":"markdown","source":["### Loss function\n","* 손실 함수는 모델의 예측이 정답에서 얼마나 멀리 떨어져 있는지 알려줌.\n","* PyTorch에는 일반적인 MSE(평균 제곱 오류 = L2 Norm), 교차 엔트로피 손실 및 음의 우도 손실(classifier에 유용함) 등을 포함한 다양한 손실 함수가 포함되어 있음."],"metadata":{"id":"Iob0nUWl-TsO"}},{"cell_type":"code","source":[],"metadata":{"id":"jApi0dhP-ufB"},"execution_count":null,"outputs":[]}]}